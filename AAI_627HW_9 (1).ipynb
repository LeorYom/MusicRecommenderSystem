{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Authors: Leor Yomtobian and Yash Surve"
      ],
      "metadata": {
        "id": "t2bXjfTh6kx7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this code is using Logistic Regression as the Classifier\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# File paths\n",
        "file_name_test = 'testTrack_hierarchy.txt'\n",
        "file_name_train = 'trainIdx2_matrix.txt'\n",
        "ground_truth_file = 'test2_new.txt'\n",
        "output_file = 'submission_lr_optimized_v8.csv'\n",
        "\n",
        "# Load ground truth\n",
        "print(\"Loading ground truth...\")\n",
        "ground_truth = {}\n",
        "with open(ground_truth_file, 'r') as f:\n",
        "    for line in f:\n",
        "        userID, trackID, label = line.strip().split('|')\n",
        "        ground_truth[f\"{userID}_{trackID}\"] = int(label)\n",
        "gt_users = set(k.split('_')[0] for k in ground_truth.keys())\n",
        "gt_tracks = set(k.split('_')[1] for k in ground_truth.keys())\n",
        "print(f\"Loaded {len(ground_truth)} ground truth labels ({sum(1 for v in ground_truth.values() if v == 1)} positive, {sum(1 for v in ground_truth.values() if v == 0)} negative).\")\n",
        "print(f\"Unique users in ground truth: {len(gt_users)}\")\n",
        "\n",
        "# Load test hierarchy\n",
        "print(\"Loading test hierarchy for trackIDs...\")\n",
        "test_tracks = {}\n",
        "with open(file_name_test, 'r') as fTest:\n",
        "    for line in fTest:\n",
        "        parts = line.strip().split('|')\n",
        "        userID = parts[0]\n",
        "        trackID = parts[1]\n",
        "        albumID = parts[2] if parts[2] != \"None\" else None\n",
        "        artistID = parts[3] if len(parts) > 3 and parts[3] != \"None\" else None\n",
        "        genreIDs = parts[4:] if len(parts) > 4 else []\n",
        "        test_tracks[f\"{userID}_{trackID}\"] = {\n",
        "            'trackID': trackID,\n",
        "            'albumID': albumID,\n",
        "            'artistID': artistID,\n",
        "            'genreIDs': genreIDs\n",
        "        }\n",
        "test_track_ids = set(t['trackID'] for t in test_tracks.values())\n",
        "print(f\"Loaded {len(test_tracks)} user-track pairs.\")\n",
        "print(f\"Ground truth tracks in test hierarchy: {len(gt_tracks & test_track_ids)}/{len(gt_tracks)}\")\n",
        "\n",
        "# Load training data\n",
        "print(\"Reading training data...\")\n",
        "train_data = {}\n",
        "user_ratings = {}\n",
        "all_scores = []\n",
        "artist_global_scores = {}\n",
        "\n",
        "with open(file_name_train, 'r') as fTrain:\n",
        "    for line in fTrain:\n",
        "        userID, itemID, score = line.strip().split('|')\n",
        "        score = int(score)\n",
        "        if userID not in train_data:\n",
        "            train_data[userID] = {}\n",
        "        train_data[userID][itemID] = score\n",
        "        all_scores.append(score)\n",
        "        if userID not in user_ratings:\n",
        "            user_ratings[userID] = []\n",
        "        user_ratings[userID].append(score)\n",
        "        if itemID.startswith('artist_'):\n",
        "            if itemID not in artist_global_scores:\n",
        "                artist_global_scores[itemID] = []\n",
        "            artist_global_scores[itemID].append(score)\n",
        "\n",
        "global_avg_score = np.mean(all_scores) if all_scores else 0\n",
        "user_avg_scores = {\n",
        "    uid: np.mean(scores) if scores else global_avg_score for uid, scores in user_ratings.items()\n",
        "}\n",
        "user_rating_count = {\n",
        "    uid: len(scores) for uid, scores in user_ratings.items()\n",
        "}\n",
        "user_rating_variance = {\n",
        "    uid: np.std(scores) if scores else 0 for uid, scores in user_ratings.items()\n",
        "}\n",
        "# Log-transform and cap user_rating_count\n",
        "user_rating_count = {uid: min(np.log1p(count), 5.0) for uid, count in user_rating_count.items()}\n",
        "# Global artist averages for cold-start\n",
        "artist_global_avg = {\n",
        "    aid: np.mean(scores) if scores else global_avg_score for aid, scores in artist_global_scores.items()\n",
        "}\n",
        "print(f\"Training data loaded. Global average score: {global_avg_score:.2f}\")\n",
        "print(f\"User variance mean: {np.mean(list(user_rating_variance.values())):.2f}, std: {np.std(list(user_rating_variance.values())):.2f}\")\n",
        "print(f\"User rating count mean: {np.mean(list(user_rating_count.values())):.2f}, std: {np.std(list(user_rating_count.values())):.2f}\")\n",
        "user_rating_coverage = {uid: sum(1 for tid in gt_tracks if tid in train_data.get(uid, {})) for uid in gt_users}\n",
        "print(f\"Users with ratings for ground truth tracks: {sum(1 for v in user_rating_coverage.values() if v > 0)}/{len(gt_users)}\")\n",
        "\n",
        "# Debug track IDs\n",
        "sample_train_items = []\n",
        "for uid in list(train_data.keys())[:5]:\n",
        "    sample_train_items.extend(list(train_data[uid].keys())[:5])\n",
        "print(f\"Sample training item IDs: {sample_train_items[:10]}\")\n",
        "print(f\"Sample ground truth track IDs: {list(gt_tracks)[:5]}\")\n",
        "\n",
        "# Prepare training data\n",
        "print(\"Preparing training data for LR...\")\n",
        "X_train = []\n",
        "y_train = []\n",
        "users_processed = set()\n",
        "feature_stats = {\n",
        "    'artist': [], 'genre': [], 'has_rating': [], 'track_score_missing': [],\n",
        "    'album_score_missing': [], 'artist_score_missing': [], 'genre_score_missing': [],\n",
        "    'artist_score_weighted': [], 'user_variance': [], 'user_rating_count': []\n",
        "}\n",
        "raw_counts = {'track': 0, 'album': 0, 'artist': 0, 'genre': 0}\n",
        "label_ratings = {\n",
        "    'positive': {'artist': [], 'genre': [], 'artist_score_weighted': []},\n",
        "    'negative': {'artist': [], 'genre': [], 'artist_score_weighted': []}\n",
        "}\n",
        "track_label_counts = {tid: {'pos': 0, 'neg': 0} for tid in gt_tracks}\n",
        "track_rating_debug = []\n",
        "\n",
        "for userID in gt_users:\n",
        "    u_ratings = train_data.get(userID, {})\n",
        "    user_track_keys = [k for k in ground_truth.keys() if k.startswith(userID + '_')]\n",
        "    if not user_track_keys:\n",
        "        print(f\"Warning: User {userID} has no tracks in ground truth. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    for track_key in user_track_keys:\n",
        "        trackID = track_key.split('_')[1]\n",
        "        label = ground_truth[track_key]\n",
        "        track_label_counts[trackID]['pos' if label == 1 else 'neg'] += 1\n",
        "\n",
        "        # Extract features\n",
        "        t_data = test_tracks.get(track_key, {'trackID': trackID, 'albumID': None, 'artistID': None, 'genreIDs': []})\n",
        "        # Try raw trackID and prefixed versions\n",
        "        raw_track_score = u_ratings.get(t_data['trackID'], u_ratings.get(f\"track_{t_data['trackID']}\", 0))\n",
        "        raw_album_score = u_ratings.get(t_data['albumID'], 0) if t_data['albumID'] else 0\n",
        "        raw_artist_score = u_ratings.get(t_data['artistID'], 0) if t_data['artistID'] else 0\n",
        "        genre_scores = [u_ratings.get(gid, 0) for gid in t_data['genreIDs']]\n",
        "        genre_rated = [s for s in genre_scores if s > 0]\n",
        "        raw_genre_score = np.mean(genre_rated) if genre_rated else 0\n",
        "\n",
        "        # Debug track ratings\n",
        "        track_rating_debug.append(raw_track_score)\n",
        "        if raw_track_score > 0:\n",
        "            raw_counts['track'] += 1\n",
        "        if raw_album_score > 0:\n",
        "            raw_counts['album'] += 1\n",
        "        if raw_artist_score > 0:\n",
        "            raw_counts['artist'] += 1\n",
        "        if raw_genre_score > 0:\n",
        "            raw_counts['genre'] += 1\n",
        "\n",
        "        has_rating = 1 if raw_track_score > 0 else 0\n",
        "        track_score_missing = 1 if raw_track_score == 0 else 0\n",
        "        album_score_missing = 1 if raw_album_score == 0 else 0\n",
        "        artist_score_missing = 1 if raw_artist_score == 0 else 0\n",
        "        genre_score_missing = 1 if not genre_rated else 0\n",
        "        artist_score_weighted = raw_artist_score * (1 - artist_score_missing)\n",
        "        user_variance = user_rating_variance.get(userID, 0)\n",
        "        user_rcount = user_rating_count.get(userID, 0)\n",
        "        default_score = user_avg_scores.get(userID, global_avg_score)\n",
        "        artist_score = min(raw_artist_score, 100) if raw_artist_score > 0 else default_score\n",
        "        genre_score = min(raw_genre_score, 100) if raw_genre_score > 0 else default_score\n",
        "\n",
        "        features = [\n",
        "            artist_score,\n",
        "            genre_score,\n",
        "            has_rating,\n",
        "            track_score_missing,\n",
        "            album_score_missing,\n",
        "            artist_score_missing,\n",
        "            genre_score_missing,\n",
        "            artist_score_weighted,\n",
        "            user_variance,\n",
        "            user_rcount\n",
        "        ]\n",
        "        X_train.append(features)\n",
        "        y_train.append(label)\n",
        "\n",
        "        # Track feature statistics and label ratings\n",
        "        feature_stats['artist'].append(artist_score)\n",
        "        feature_stats['genre'].append(genre_score)\n",
        "        feature_stats['has_rating'].append(has_rating)\n",
        "        feature_stats['track_score_missing'].append(track_score_missing)\n",
        "        feature_stats['album_score_missing'].append(album_score_missing)\n",
        "        feature_stats['artist_score_missing'].append(artist_score_missing)\n",
        "        feature_stats['genre_score_missing'].append(genre_score_missing)\n",
        "        feature_stats['artist_score_weighted'].append(artist_score_weighted)\n",
        "        feature_stats['user_variance'].append(user_variance)\n",
        "        feature_stats['user_rating_count'].append(user_rcount)\n",
        "        label_ratings['positive' if label == 1 else 'negative']['artist'].append(artist_score)\n",
        "        label_ratings['positive' if label == 1 else 'negative']['genre'].append(genre_score)\n",
        "        label_ratings['positive' if label == 1 else 'negative']['artist_score_weighted'].append(artist_score_weighted)\n",
        "\n",
        "    users_processed.add(userID)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "print(f\"Prepared {len(X_train)} training samples from {len(users_processed)} users.\")\n",
        "print(\"Feature statistics (non-zero counts):\")\n",
        "for fname, fvals in feature_stats.items():\n",
        "    if fname in ['has_rating', 'track_score_missing', 'album_score_missing', 'artist_score_missing', 'genre_score_missing']:\n",
        "        non_zero = sum(1 for v in fvals if v != 0)\n",
        "    else:\n",
        "        non_zero = sum(1 for v in fvals if v != global_avg_score and v != 0)\n",
        "    print(f\"  {fname}: {non_zero}/{len(fvals)} non-zero values\")\n",
        "print(\"Raw rating counts (before defaulting):\")\n",
        "for fname, count in raw_counts.items():\n",
        "    print(f\"  {fname}: {count}/{len(X_train)} non-zero values\")\n",
        "print(f\"Track rating debug: {sum(1 for v in track_rating_debug if v > 0)}/{len(track_rating_debug)} non-zero raw_track_score\")\n",
        "for ftype in ['artist', 'genre', 'artist_score_weighted']:\n",
        "    print(f\"Average {ftype}_score for positive labels: {np.mean(label_ratings['positive'][ftype]):.2f}\")\n",
        "    print(f\"Average {ftype}_score for negative labels: {np.mean(label_ratings['negative'][ftype]):.2f}\")\n",
        "    print(f\"Std {ftype}_score for positive labels: {np.std(label_ratings['positive'][ftype]):.2f}\")\n",
        "    print(f\"Std {ftype}_score for negative labels: {np.std(label_ratings['negative'][ftype]):.2f}\")\n",
        "mixed_label_tracks = sum(1 for v in track_label_counts.values() if v['pos'] > 0 and v['neg'] > 0)\n",
        "print(f\"Tracks with mixed labels: {mixed_label_tracks}/{len(gt_tracks)}\")\n",
        "# Feature correlations\n",
        "feature_names = ['artist', 'genre', 'has_rating', 'track_score_missing', 'album_score_missing', 'artist_score_missing', 'genre_score_missing', 'artist_score_weighted', 'user_variance', 'user_rating_count']\n",
        "corr_matrix = np.corrcoef(X_train.T)\n",
        "print(\"Feature correlations:\")\n",
        "for i, fname in enumerate(feature_names):\n",
        "    for j in range(i+1, len(feature_names)):\n",
        "        if abs(corr_matrix[i, j]) > 0.5:\n",
        "            print(f\"  {fname} vs {feature_names[j]}: {corr_matrix[i, j]:.2f}\")\n",
        "\n",
        "# Train Logistic Regression model\n",
        "print(\"Training Logistic Regression model...\")\n",
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "lr_model = LogisticRegression(random_state=42, max_iter=2000, solver='lbfgs', class_weight='balanced', C=2.0)\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "cv_scores = cross_val_score(lr_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "cv_precision_scores = cross_val_score(lr_model, X_train_scaled, y_train, cv=5, scoring='precision')\n",
        "print(\"Model training completed.\")\n",
        "print(\"Feature coefficients:\", dict(zip(feature_names, lr_model.coef_[0])))\n",
        "print(\"Feature means after scaling:\", np.mean(X_train_scaled, axis=0))\n",
        "print(\"Feature stds after scaling:\", np.std(X_train_scaled, axis=0))\n",
        "print(f\"Cross-validation accuracy: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
        "print(f\"Cross-validation Precision@3: {np.mean(cv_precision_scores):.4f} ± {np.std(cv_precision_scores):.4f}\")\n",
        "\n",
        "# Output predictions\n",
        "fOut = open(output_file, 'w')\n",
        "fOut.write(\"TrackID,Predictor\\n\")\n",
        "written_keys = set()\n",
        "unseen_users = 0\n",
        "cold_start_preds = 0\n",
        "\n",
        "print(\"Processing test data...\")\n",
        "with open(file_name_test, 'r') as fTest:\n",
        "    lastUserID = None\n",
        "    user_tracks = []\n",
        "    user_metadata = []\n",
        "\n",
        "    for line in fTest:\n",
        "        parts = line.strip().split('|')\n",
        "        userID = parts[0]\n",
        "        trackID = parts[1]\n",
        "        albumID = parts[2] if parts[2] != \"None\" else None\n",
        "        artistID = parts[3] if len(parts) > 3 and parts[3] != \"None\" else None\n",
        "        genreIDs = parts[4:] if len(parts) > 4 else []\n",
        "\n",
        "        if userID != lastUserID and lastUserID is not None and user_tracks:\n",
        "            u_ratings = train_data.get(lastUserID, {})\n",
        "            default_score = user_avg_scores.get(lastUserID, global_avg_score)\n",
        "            if lastUserID not in train_data or not u_ratings:\n",
        "                unseen_users += 1\n",
        "                # Fallback to weighted global artist_score\n",
        "                artist_scores = []\n",
        "                for i, t_data in enumerate(user_metadata):\n",
        "                    artist_score = artist_global_avg.get(t_data['artistID'], global_avg_score) if t_data['artistID'] else global_avg_score\n",
        "                    weight = 1.2 if artist_score > global_avg_score else 0.8\n",
        "                    artist_scores.append(artist_score * weight)\n",
        "                top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "                preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "                cold_start_preds += sum(preds)\n",
        "            else:\n",
        "                X_test = []\n",
        "                for i, t_data in enumerate(user_metadata):\n",
        "                    tID = t_data['trackID']\n",
        "                    raw_track_score = u_ratings.get(tID, u_ratings.get(f\"track_{tID}\", 0))\n",
        "                    raw_album_score = u_ratings.get(t_data['albumID'], 0) if t_data['albumID'] else 0\n",
        "                    raw_artist_score = u_ratings.get(t_data['artistID'], 0) if t_data['artistID'] else 0\n",
        "                    genre_scores = [u_ratings.get(gid, 0) for gid in t_data['genreIDs']]\n",
        "                    genre_rated = [s for s in genre_scores if s > 0]\n",
        "                    raw_genre_score = np.mean(genre_rated) if genre_rated else 0\n",
        "\n",
        "                    has_rating = 1 if raw_track_score > 0 else 0\n",
        "                    track_score_missing = 1 if raw_track_score == 0 else 0\n",
        "                    album_score_missing = 1 if raw_album_score == 0 else 0\n",
        "                    artist_score_missing = 1 if raw_artist_score == 0 else 0\n",
        "                    genre_score_missing = 1 if not genre_rated else 0\n",
        "                    artist_score_weighted = raw_artist_score * (1 - artist_score_missing)\n",
        "                    user_variance = user_rating_variance.get(lastUserID, 0)\n",
        "                    user_rcount = user_rating_count.get(lastUserID, 0)\n",
        "                    artist_score = min(raw_artist_score, 100) if raw_artist_score > 0 else default_score\n",
        "                    genre_score = min(raw_genre_score, 100) if raw_genre_score > 0 else default_score\n",
        "\n",
        "                    features = [\n",
        "                        artist_score,\n",
        "                        genre_score,\n",
        "                        has_rating,\n",
        "                        track_score_missing,\n",
        "                        album_score_missing,\n",
        "                        artist_score_missing,\n",
        "                        genre_score_missing,\n",
        "                        artist_score_weighted,\n",
        "                        user_variance,\n",
        "                        user_rcount\n",
        "                    ]\n",
        "                    X_test.append(features)\n",
        "\n",
        "                X_test = np.array(X_test)\n",
        "                X_test_scaled = scaler.transform(X_test)\n",
        "                probs = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
        "                prob_diff = np.max(probs) - np.min(probs)\n",
        "                top3 = np.argsort(-probs)[:3 if prob_diff > 0.25 else 2]\n",
        "                preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "                if prob_diff < 0.1:  # Fallback for low confidence\n",
        "                    artist_scores = [X_test[i][0] * (1 - X_test[i][5]) for i in range(len(X_test))]\n",
        "                    top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "                    preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "                    cold_start_preds += sum(preds)\n",
        "\n",
        "            for i, t_data in enumerate(user_metadata):\n",
        "                t_key = f\"{lastUserID}_{t_data['trackID']}\"\n",
        "                if t_key not in written_keys:\n",
        "                    fOut.write(f\"{t_key},{preds[i]}\\n\")\n",
        "                    written_keys.add(t_key)\n",
        "\n",
        "            user_tracks = []\n",
        "            user_metadata = []\n",
        "\n",
        "        user_tracks.append(trackID)\n",
        "        user_metadata.append({'trackID': trackID, 'albumID': albumID, 'artistID': artistID, 'genreIDs': genreIDs})\n",
        "        lastUserID = userID\n",
        "\n",
        "    # Handle last user block\n",
        "    if user_tracks:\n",
        "        u_ratings = train_data.get(lastUserID, {})\n",
        "        default_score = user_avg_scores.get(lastUserID, global_avg_score)\n",
        "        if lastUserID not in train_data or not u_ratings:\n",
        "            unseen_users += 1\n",
        "            artist_scores = []\n",
        "            for i, t_data in enumerate(user_metadata):\n",
        "                artist_score = artist_global_avg.get(t_data['artistID'], global_avg_score) if t_data['artistID'] else global_avg_score\n",
        "                weight = 1.2 if artist_score > global_avg_score else 0.8\n",
        "                artist_scores.append(artist_score * weight)\n",
        "            top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "            preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "            cold_start_preds += sum(preds)\n",
        "        else:\n",
        "            X_test = []\n",
        "            for i, t_data in enumerate(user_metadata):\n",
        "                tID = t_data['trackID']\n",
        "                raw_track_score = u_ratings.get(tID, u_ratings.get(f\"track_{tID}\", 0))\n",
        "                raw_album_score = u_ratings.get(t_data['albumID'], 0) if t_data['albumID'] else 0\n",
        "                raw_artist_score = u_ratings.get(t_data['artistID'], 0) if t_data['artistID'] else 0\n",
        "                genre_scores = [u_ratings.get(gid, 0) for gid in t_data['genreIDs']]\n",
        "                genre_rated = [s for s in genre_scores if s > 0]\n",
        "                raw_genre_score = np.mean(genre_rated) if genre_rated else 0\n",
        "\n",
        "                has_rating = 1 if raw_track_score > 0 else 0\n",
        "                track_score_missing = 1 if raw_track_score == 0 else 0\n",
        "                album_score_missing = 1 if raw_album_score == 0 else 0\n",
        "                artist_score_missing = 1 if raw_artist_score == 0 else 0\n",
        "                genre_score_missing = 1 if not genre_rated else 0\n",
        "                artist_score_weighted = raw_artist_score * (1 - artist_score_missing)\n",
        "                user_variance = user_rating_variance.get(lastUserID, 0)\n",
        "                user_rcount = user_rating_count.get(lastUserID, 0)\n",
        "                artist_score = min(raw_artist_score, 100) if raw_artist_score > 0 else default_score\n",
        "                genre_score = min(raw_genre_score, 100) if raw_genre_score > 0 else default_score\n",
        "\n",
        "                features = [\n",
        "                    artist_score,\n",
        "                    genre_score,\n",
        "                    has_rating,\n",
        "                    track_score_missing,\n",
        "                    album_score_missing,\n",
        "                    artist_score_missing,\n",
        "                    genre_score_missing,\n",
        "                    artist_score_weighted,\n",
        "                    user_variance,\n",
        "                    user_rcount\n",
        "                ]\n",
        "                X_test.append(features)\n",
        "\n",
        "            X_test = np.array(X_test)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "            probs = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
        "            prob_diff = np.max(probs) - np.min(probs)\n",
        "            top3 = np.argsort(-probs)[:3 if prob_diff > 0.25 else 2]\n",
        "            preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "            if prob_diff < 0.1:\n",
        "                artist_scores = [X_test[i][0] * (1 - X_test[i][5]) for i in range(len(X_test))]\n",
        "                top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "                preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "                cold_start_preds += sum(preds)\n",
        "\n",
        "        for i, t_data in enumerate(user_metadata):\n",
        "            t_key = f\"{lastUserID}_{t_data['trackID']}\"\n",
        "            if t_key not in written_keys:\n",
        "                fOut.write(f\"{t_key},{preds[i]}\\n\")\n",
        "                written_keys.add(t_key)\n",
        "\n",
        "fOut.close()\n",
        "print(f\"Submission file '{output_file}' written with {len(written_keys)} predictions.\")\n",
        "print(f\"Unseen users in test set: {unseen_users}\")\n",
        "print(f\"Cold-start predictions (positive): {cold_start_preds}\")\n",
        "\n",
        "# Evaluate on ground truth\n",
        "print(\"Evaluating on ground truth...\")\n",
        "y_true = []\n",
        "y_pred = []\n",
        "eval_users = set()\n",
        "prob_dist = []\n",
        "\n",
        "for userID in gt_users:\n",
        "    user_track_keys = [k for k in ground_truth.keys() if k.startswith(userID + '_')]\n",
        "    if not user_track_keys:\n",
        "        print(f\"Warning: User {userID} has no tracks in ground truth. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    u_ratings = train_data.get(userID, {})\n",
        "    default_score = user_avg_scores.get(userID, global_avg_score)\n",
        "    X_test = []\n",
        "\n",
        "    for track_key in user_track_keys:\n",
        "        t_data = test_tracks.get(track_key, {'trackID': track_key.split('_')[1], 'albumID': None, 'artistID': None, 'genreIDs': []})\n",
        "        raw_track_score = u_ratings.get(t_data['trackID'], u_ratings.get(f\"track_{t_data['trackID']}\", 0))\n",
        "        raw_album_score = u_ratings.get(t_data['albumID'], 0) if t_data['albumID'] else 0\n",
        "        raw_artist_score = u_ratings.get(t_data['artistID'], 0) if t_data['artistID'] else 0\n",
        "        genre_scores = [u_ratings.get(gid, 0) for gid in t_data['genreIDs']]\n",
        "        genre_rated = [s for s in genre_scores if s > 0]\n",
        "        raw_genre_score = np.mean(genre_rated) if genre_rated else 0\n",
        "\n",
        "        has_rating = 1 if raw_track_score > 0 else 0\n",
        "        track_score_missing = 1 if raw_track_score == 0 else 0\n",
        "        album_score_missing = 1 if raw_album_score == 0 else 0\n",
        "        artist_score_missing = 1 if raw_artist_score == 0 else 0\n",
        "        genre_score_missing = 1 if not genre_rated else 0\n",
        "        artist_score_weighted = raw_artist_score * (1 - artist_score_missing)\n",
        "        user_variance = user_rating_variance.get(userID, 0)\n",
        "        user_rcount = user_rating_count.get(userID, 0)\n",
        "        artist_score = min(raw_artist_score, 100) if raw_artist_score > 0 else default_score\n",
        "        genre_score = min(raw_genre_score, 100) if raw_genre_score > 0 else default_score\n",
        "\n",
        "        features = [\n",
        "            artist_score,\n",
        "            genre_score,\n",
        "            has_rating,\n",
        "            track_score_missing,\n",
        "            album_score_missing,\n",
        "            artist_score_missing,\n",
        "            genre_score_missing,\n",
        "            artist_score_weighted,\n",
        "            user_variance,\n",
        "            user_rcount\n",
        "        ]\n",
        "        X_test.append(features)\n",
        "\n",
        "    X_test = np.array(X_test)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    probs = lr_model.predict_proba(X_test_scaled)[:, 1]\n",
        "    prob_diff = np.max(probs) - np.min(probs)\n",
        "    top3 = np.argsort(-probs)[:3 if prob_diff > 0.25 else 2]\n",
        "    preds = [1 if i in top3 else 0 for i in range(len(user_track_keys))]\n",
        "    if prob_diff < 0.1:\n",
        "        artist_scores = [X_test[i][0] * (1 - X_test[i][5]) for i in range(len(X_test))]\n",
        "        top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "        preds = [1 if i in top3 else 0 for i in range(len(user_track_keys))]\n",
        "        cold_start_preds += sum(preds)\n",
        "\n",
        "    y_pred.extend(preds)\n",
        "    y_true.extend([ground_truth[k] for k in user_track_keys])\n",
        "    prob_dist.extend(probs)\n",
        "    eval_users.add(userID)\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='binary')\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(f\"Ground truth accuracy: {accuracy:.4f} over {len(y_true)} samples from {len(eval_users)} users.\")\n",
        "print(f\"Precision@3: {precision:.4f}\")\n",
        "print(f\"Confusion matrix:\\n{cm}\")\n",
        "print(f\"Prediction probability distribution: mean={np.mean(prob_dist):.4f}, std={np.std(prob_dist):.4f}, min={np.min(prob_dist):.4f}, max={np.max(prob_dist):.4f}\")"
      ],
      "metadata": {
        "id": "rvUwGdPk6qhZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this code is using Random Forest as the Classifier\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, RandomizedSearchCV\n",
        "\n",
        "# File paths\n",
        "file_name_test = 'testTrack_hierarchy.txt'\n",
        "file_name_train = 'trainIdx2_matrix.txt'\n",
        "ground_truth_file = 'test2_new.txt'\n",
        "output_file = 'submission_rf_optimized_v13.csv'\n",
        "\n",
        "# Load ground truth\n",
        "print(\"Loading ground truth...\")\n",
        "ground_truth = {}\n",
        "with open(ground_truth_file, 'r') as f:\n",
        "    for line in f:\n",
        "        userID, trackID, label = line.strip().split('|')\n",
        "        ground_truth[f\"{userID}_{trackID}\"] = int(label)\n",
        "gt_users = set(k.split('_')[0] for k in ground_truth.keys())\n",
        "gt_tracks = set(k.split('_')[1] for k in ground_truth.keys())\n",
        "print(f\"Loaded {len(ground_truth)} ground truth labels ({sum(1 for v in ground_truth.values() if v == 1)} positive, {sum(1 for v in ground_truth.values() if v == 0)} negative).\")\n",
        "print(f\"Unique users in ground truth: {len(gt_users)}\")\n",
        "\n",
        "# Load test hierarchy\n",
        "print(\"Loading test hierarchy for trackIDs...\")\n",
        "test_tracks = {}\n",
        "with open(file_name_test, 'r') as fTest:\n",
        "    for line in fTest:\n",
        "        parts = line.strip().split('|')\n",
        "        userID = parts[0]\n",
        "        trackID = parts[1]\n",
        "        albumID = parts[2] if parts[2] != \"None\" else None\n",
        "        artistID = parts[3] if len(parts) > 3 and parts[3] != \"None\" else None\n",
        "        genreIDs = parts[4:] if len(parts) > 4 else []\n",
        "        test_tracks[f\"{userID}_{trackID}\"] = {\n",
        "            'trackID': trackID,\n",
        "            'albumID': albumID,\n",
        "            'artistID': artistID,\n",
        "            'genreIDs': genreIDs\n",
        "        }\n",
        "test_track_ids = set(t['trackID'] for t in test_tracks.values())\n",
        "print(f\"Loaded {len(test_tracks)} user-track pairs.\")\n",
        "print(f\"Ground truth tracks in test hierarchy: {len(gt_tracks & test_track_ids)}/{len(gt_tracks)}\")\n",
        "\n",
        "# Load training data\n",
        "print(\"Reading training data...\")\n",
        "train_data = {}\n",
        "user_ratings = {}\n",
        "all_scores = []\n",
        "artist_global_scores = {}\n",
        "genre_global_scores = {}\n",
        "\n",
        "with open(file_name_train, 'r') as fTrain:\n",
        "    for line in fTrain:\n",
        "        userID, itemID, score = line.strip().split('|')\n",
        "        score = int(score)\n",
        "        if userID not in train_data:\n",
        "            train_data[userID] = {}\n",
        "        train_data[userID][itemID] = score\n",
        "        all_scores.append(score)\n",
        "        if userID not in user_ratings:\n",
        "            user_ratings[userID] = []\n",
        "        user_ratings[userID].append(score)\n",
        "        if itemID.startswith('artist_'):\n",
        "            if itemID not in artist_global_scores:\n",
        "                artist_global_scores[itemID] = []\n",
        "            artist_global_scores[itemID].append(score)\n",
        "        if itemID.startswith('genre_'):\n",
        "            if itemID not in genre_global_scores:\n",
        "                genre_global_scores[itemID] = []\n",
        "            genre_global_scores[itemID].append(score)\n",
        "\n",
        "global_avg_score = np.mean(all_scores) if all_scores else 0\n",
        "user_avg_scores = {\n",
        "    uid: np.mean(scores) if scores else global_avg_score for uid, scores in user_ratings.items()\n",
        "}\n",
        "user_rating_count = {\n",
        "    uid: len(scores) for uid, scores in user_ratings.items()\n",
        "}\n",
        "user_rating_variance = {\n",
        "    uid: np.std(scores) if scores else 0 for uid, scores in user_ratings.items()\n",
        "}\n",
        "# Log-transform and cap user_rating_count\n",
        "user_rating_count = {uid: min(np.log1p(count), 5.0) for uid, count in user_rating_count.items()}\n",
        "# Global artist and genre averages for new features and cold-start\n",
        "artist_global_avg = {\n",
        "    aid: np.mean(scores) if scores else global_avg_score for aid, scores in artist_global_scores.items()\n",
        "}\n",
        "genre_global_avg = {\n",
        "    gid: np.mean(scores) if scores else global_avg_score for gid, scores in genre_global_scores.items()\n",
        "}\n",
        "print(f\"Training data loaded. Global average score: {global_avg_score:.2f}\")\n",
        "print(f\"User variance mean: {np.mean(list(user_rating_variance.values())):.2f}, std: {np.std(list(user_rating_variance.values())):.2f}\")\n",
        "print(f\"User rating count mean: {np.mean(list(user_rating_count.values())):.2f}, std: {np.std(list(user_rating_count.values())):.2f}\")\n",
        "user_rating_coverage = {uid: sum(1 for tid in gt_tracks if tid in train_data.get(uid, {})) for uid in gt_users}\n",
        "print(f\"Users with ratings for ground truth tracks: {sum(1 for v in user_rating_coverage.values() if v > 0)}/{len(gt_users)}\")\n",
        "\n",
        "# Debug track IDs\n",
        "sample_train_items = []\n",
        "for uid in list(train_data.keys())[:5]:\n",
        "    sample_train_items.extend(list(train_data[uid].keys())[:5])\n",
        "print(f\"Sample training item IDs: {sample_train_items[:10]}\")\n",
        "print(f\"Sample ground truth track IDs: {list(gt_tracks)[:5]}\")\n",
        "\n",
        "# Prepare training data\n",
        "print(\"Preparing training data for RF...\")\n",
        "X_train = []\n",
        "y_train = []\n",
        "users_processed = set()\n",
        "feature_stats = {\n",
        "    'artist': [], 'genre': [], 'album_score_missing': [], 'artist_score_missing': [],\n",
        "    'genre_score_missing': [], 'artist_score_weighted': [], 'user_variance': [],\n",
        "    'user_rating_count': [], 'genre_count': [], 'artist_popularity': [], 'genre_score_weighted': []\n",
        "}\n",
        "raw_counts = {'track': 0, 'album': 0, 'artist': 0, 'genre': 0}\n",
        "label_ratings = {\n",
        "    'positive': {'artist': [], 'genre': [], 'artist_score_weighted': [], 'genre_count': [], 'artist_popularity': [], 'genre_score_weighted': []},\n",
        "    'negative': {'artist': [], 'genre': [], 'artist_score_weighted': [], 'genre_count': [], 'artist_popularity': [], 'genre_score_weighted': []}\n",
        "}\n",
        "track_label_counts = {tid: {'pos': 0, 'neg': 0} for tid in gt_tracks}\n",
        "track_rating_debug = []\n",
        "\n",
        "for userID in gt_users:\n",
        "    u_ratings = train_data.get(userID, {})\n",
        "    user_track_keys = [k for k in ground_truth.keys() if k.startswith(userID + '_')]\n",
        "    if not user_track_keys:\n",
        "        print(f\"Warning: User {userID} has no tracks in ground truth. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    for track_key in user_track_keys:\n",
        "        trackID = track_key.split('_')[1]\n",
        "        label = ground_truth[track_key]\n",
        "        track_label_counts[trackID]['pos' if label == 1 else 'neg'] += 1\n",
        "\n",
        "        # Extract features\n",
        "        t_data = test_tracks.get(track_key, {'trackID': trackID, 'albumID': None, 'artistID': None, 'genreIDs': []})\n",
        "        raw_track_score = u_ratings.get(t_data['trackID'], u_ratings.get(f\"track_{t_data['trackID']}\", 0))\n",
        "        raw_album_score = u_ratings.get(t_data['albumID'], 0) if t_data['albumID'] else 0\n",
        "        raw_artist_score = u_ratings.get(t_data['artistID'], 0) if t_data['artistID'] else 0\n",
        "        genre_scores = [u_ratings.get(gid, 0) for gid in t_data['genreIDs']]\n",
        "        genre_rated = [s for s in genre_scores if s > 0]\n",
        "        raw_genre_score = np.mean(genre_rated) if genre_rated else 0\n",
        "        genre_count = len(t_data['genreIDs'])\n",
        "        # New features\n",
        "        artist_popularity = artist_global_avg.get(t_data['artistID'], global_avg_score) if t_data['artistID'] else global_avg_score\n",
        "        genre_score_weighted = raw_genre_score * (len(genre_rated) / len(t_data['genreIDs']) if t_data['genreIDs'] else 0)\n",
        "\n",
        "        # Debug track ratings\n",
        "        track_rating_debug.append(raw_track_score)\n",
        "        if raw_track_score > 0:\n",
        "            raw_counts['track'] += 1\n",
        "        if raw_album_score > 0:\n",
        "            raw_counts['album'] += 1\n",
        "        if raw_artist_score > 0:\n",
        "            raw_counts['artist'] += 1\n",
        "        if raw_genre_score > 0:\n",
        "            raw_counts['genre'] += 1\n",
        "\n",
        "        album_score_missing = 1 if raw_album_score == 0 else 0\n",
        "        artist_score_missing = 1 if raw_artist_score == 0 else 0\n",
        "        genre_score_missing = 1 if not genre_rated else 0\n",
        "        artist_score_weighted = raw_artist_score * (1 - artist_score_missing)\n",
        "        user_variance = user_rating_variance.get(userID, 0)\n",
        "        user_rcount = user_rating_count.get(userID, 0)\n",
        "        default_score = user_avg_scores.get(userID, global_avg_score)\n",
        "        artist_score = min(raw_artist_score, 100) if raw_artist_score > 0 else default_score\n",
        "        genre_score = min(raw_genre_score, 100) if raw_genre_score > 0 else default_score\n",
        "\n",
        "        features = [\n",
        "            artist_score,\n",
        "            genre_score,\n",
        "            album_score_missing,\n",
        "            artist_score_missing,\n",
        "            genre_score_missing,\n",
        "            artist_score_weighted,\n",
        "            user_variance,\n",
        "            user_rcount,\n",
        "            genre_count,\n",
        "            artist_popularity,\n",
        "            genre_score_weighted\n",
        "        ]\n",
        "        X_train.append(features)\n",
        "        y_train.append(label)\n",
        "\n",
        "        # Track feature statistics and label ratings\n",
        "        feature_stats['artist'].append(artist_score)\n",
        "        feature_stats['genre'].append(genre_score)\n",
        "        feature_stats['album_score_missing'].append(album_score_missing)\n",
        "        feature_stats['artist_score_missing'].append(artist_score_missing)\n",
        "        feature_stats['genre_score_missing'].append(genre_score_missing)\n",
        "        feature_stats['artist_score_weighted'].append(artist_score_weighted)\n",
        "        feature_stats['user_variance'].append(user_variance)\n",
        "        feature_stats['user_rating_count'].append(user_rcount)\n",
        "        feature_stats['genre_count'].append(genre_count)\n",
        "        feature_stats['artist_popularity'].append(artist_popularity)\n",
        "        feature_stats['genre_score_weighted'].append(genre_score_weighted)\n",
        "        label_ratings['positive' if label == 1 else 'negative']['artist'].append(artist_score)\n",
        "        label_ratings['positive' if label == 1 else 'negative']['genre'].append(genre_score)\n",
        "        label_ratings['positive' if label == 1 else 'negative']['artist_score_weighted'].append(artist_score_weighted)\n",
        "        label_ratings['positive' if label == 1 else 'negative']['genre_count'].append(genre_count)\n",
        "        label_ratings['positive' if label == 1 else 'negative']['artist_popularity'].append(artist_popularity)\n",
        "        label_ratings['positive' if label == 1 else 'negative']['genre_score_weighted'].append(genre_score_weighted)\n",
        "\n",
        "    users_processed.add(userID)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "print(f\"Prepared {len(X_train)} training samples from {len(users_processed)} users.\")\n",
        "print(\"Feature statistics (non-zero counts):\")\n",
        "for fname, fvals in feature_stats.items():\n",
        "    if fname in ['album_score_missing', 'artist_score_missing', 'genre_score_missing']:\n",
        "        non_zero = sum(1 for v in fvals if v != 0)\n",
        "    else:\n",
        "        non_zero = sum(1 for v in fvals if v != global_avg_score and v != 0)\n",
        "    print(f\"  {fname}: {non_zero}/{len(fvals)} non-zero values\")\n",
        "print(\"Raw rating counts (before defaulting):\")\n",
        "for fname, count in raw_counts.items():\n",
        "    print(f\"  {fname}: {count}/{len(X_train)} non-zero values\")\n",
        "print(f\"Track rating debug: {sum(1 for v in track_rating_debug if v > 0)}/{len(track_rating_debug)} non-zero raw_track_score\")\n",
        "for ftype in ['artist', 'genre', 'artist_score_weighted', 'genre_count', 'artist_popularity', 'genre_score_weighted']:\n",
        "    print(f\"Average {ftype}_score for positive labels: {np.mean(label_ratings['positive'][ftype]):.2f}\")\n",
        "    print(f\"Average {ftype}_score for negative labels: {np.mean(label_ratings['negative'][ftype]):.2f}\")\n",
        "    print(f\"Std {ftype}_score for positive labels: {np.std(label_ratings['positive'][ftype]):.2f}\")\n",
        "    print(f\"Std {ftype}_score for negative labels: {np.std(label_ratings['negative'][ftype]):.2f}\")\n",
        "mixed_label_tracks = sum(1 for v in track_label_counts.values() if v['pos'] > 0 and v['neg'] > 0)\n",
        "print(f\"Tracks with mixed labels: {mixed_label_tracks}/{len(gt_tracks)}\")\n",
        "# Feature correlations\n",
        "feature_names = ['artist', 'genre', 'album_score_missing', 'artist_score_missing', 'genre_score_missing', 'artist_score_weighted', 'user_variance', 'user_rating_count', 'genre_count', 'artist_popularity', 'genre_score_weighted']\n",
        "corr_matrix = np.corrcoef(X_train.T)\n",
        "print(\"Feature correlations:\")\n",
        "for i, fname in enumerate(feature_names):\n",
        "    for j in range(i+1, len(feature_names)):\n",
        "        if abs(corr_matrix[i, j]) > 0.5:\n",
        "            print(f\"  {fname} vs {feature_names[j]}: {corr_matrix[i, j]:.2f}\")\n",
        "\n",
        "# Train Random Forest model with RandomizedSearchCV\n",
        "print(\"Training Random Forest model with optimized hyperparameter tuning...\")\n",
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "rf_model = RandomForestClassifier(random_state=42, class_weight='balanced')\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300, 400],\n",
        "    'max_depth': [5, 10, 15, 20],\n",
        "    'min_samples_split': [5, 10, 20],\n",
        "    'min_samples_leaf': [2, 5, 10],\n",
        "    'max_features': ['sqrt', 'log2', 0.5, 0.7]\n",
        "}\n",
        "random_search = RandomizedSearchCV(rf_model, param_distributions=param_dist, n_iter=50, cv=5, scoring='precision', n_jobs=-1, random_state=42)\n",
        "random_search.fit(X_train_scaled, y_train)\n",
        "rf_model = random_search.best_estimator_\n",
        "cv_scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "cv_precision_scores = cross_val_score(rf_model, X_train_scaled, y_train, cv=5, scoring='precision')\n",
        "print(\"Model training completed.\")\n",
        "print(f\"Best hyperparameters: {random_search.best_params_}\")\n",
        "print(\"Feature importances:\", dict(zip(feature_names, rf_model.feature_importances_)))\n",
        "print(\"Feature means after scaling:\", np.mean(X_train_scaled, axis=0))\n",
        "print(\"Feature stds after scaling:\", np.std(X_train_scaled, axis=0))\n",
        "print(f\"Cross-validation accuracy: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
        "print(f\"Cross-validation Precision@3: {np.mean(cv_precision_scores):.4f} ± {np.std(cv_precision_scores):.4f}\")\n",
        "\n",
        "# Output predictions\n",
        "fOut = open(output_file, 'w')\n",
        "fOut.write(\"TrackID,Predictor\\n\")\n",
        "written_keys = set()\n",
        "unseen_users = 0\n",
        "cold_start_preds = 0\n",
        "\n",
        "print(\"Processing test data...\")\n",
        "with open(file_name_test, 'r') as fTest:\n",
        "    lastUserID = None\n",
        "    user_tracks = []\n",
        "    user_metadata = []\n",
        "\n",
        "    for line in fTest:\n",
        "        parts = line.strip().split('|')\n",
        "        userID = parts[0]\n",
        "        trackID = parts[1]\n",
        "        albumID = parts[2] if parts[2] != \"None\" else None\n",
        "        artistID = parts[3] if len(parts) > 3 and parts[3] != \"None\" else None\n",
        "        genreIDs = parts[4:] if len(parts) > 4 else []\n",
        "\n",
        "        if userID != lastUserID and lastUserID is not None and user_tracks:\n",
        "            u_ratings = train_data.get(lastUserID, {})\n",
        "            default_score = user_avg_scores.get(lastUserID, global_avg_score)\n",
        "            if lastUserID not in train_data or not u_ratings:\n",
        "                unseen_users += 1\n",
        "                # Fallback to weighted global artist_score\n",
        "                artist_scores = []\n",
        "                for i, t_data in enumerate(user_metadata):\n",
        "                    artist_score = artist_global_avg.get(t_data['artistID'], global_avg_score) if t_data['artistID'] else global_avg_score\n",
        "                    weight = 1.2 if artist_score > global_avg_score else 0.8\n",
        "                    artist_scores.append(artist_score * weight)\n",
        "                top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "                preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "                cold_start_preds += sum(preds)\n",
        "            else:\n",
        "                X_test = []\n",
        "                for i, t_data in enumerate(user_metadata):\n",
        "                    tID = t_data['trackID']\n",
        "                    raw_track_score = u_ratings.get(tID, u_ratings.get(f\"track_{tID}\", 0))\n",
        "                    raw_album_score = u_ratings.get(t_data['albumID'], 0) if t_data['albumID'] else 0\n",
        "                    raw_artist_score = u_ratings.get(t_data['artistID'], 0) if t_data['artistID'] else 0\n",
        "                    genre_scores = [u_ratings.get(gid, 0) for gid in t_data['genreIDs']]\n",
        "                    genre_rated = [s for s in genre_scores if s > 0]\n",
        "                    raw_genre_score = np.mean(genre_rated) if genre_rated else 0\n",
        "                    genre_count = len(t_data['genreIDs'])\n",
        "                    artist_popularity = artist_global_avg.get(t_data['artistID'], global_avg_score) if t_data['artistID'] else global_avg_score\n",
        "                    genre_score_weighted = raw_genre_score * (len(genre_rated) / len(t_data['genreIDs']) if t_data['genreIDs'] else 0)\n",
        "\n",
        "                    album_score_missing = 1 if raw_album_score == 0 else 0\n",
        "                    artist_score_missing = 1 if raw_artist_score == 0 else 0\n",
        "                    genre_score_missing = 1 if not genre_rated else 0\n",
        "                    artist_score_weighted = raw_artist_score * (1 - artist_score_missing)\n",
        "                    user_variance = user_rating_variance.get(lastUserID, 0)\n",
        "                    user_rcount = user_rating_count.get(lastUserID, 0)\n",
        "                    artist_score = min(raw_artist_score, 100) if raw_artist_score > 0 else default_score\n",
        "                    genre_score = min(raw_genre_score, 100) if raw_genre_score > 0 else default_score\n",
        "\n",
        "                    features = [\n",
        "                        artist_score,\n",
        "                        genre_score,\n",
        "                        album_score_missing,\n",
        "                        artist_score_missing,\n",
        "                        genre_score_missing,\n",
        "                        artist_score_weighted,\n",
        "                        user_variance,\n",
        "                        user_rcount,\n",
        "                        genre_count,\n",
        "                        artist_popularity,\n",
        "                        genre_score_weighted\n",
        "                    ]\n",
        "                    X_test.append(features)\n",
        "\n",
        "                X_test = np.array(X_test)\n",
        "                X_test_scaled = scaler.transform(X_test)\n",
        "                probs = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "                prob_diff = np.max(probs) - np.min(probs)\n",
        "                top3 = np.argsort(-probs)[:3]\n",
        "                preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "                if prob_diff < 0.03:\n",
        "                    artist_scores = [X_test[i][0] * (1 - X_test[i][3]) for i in range(len(X_test))]\n",
        "                    top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "                    preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "                    cold_start_preds += sum(preds)\n",
        "\n",
        "            for i, t_data in enumerate(user_metadata):\n",
        "                t_key = f\"{lastUserID}_{t_data['trackID']}\"\n",
        "                if t_key not in written_keys:\n",
        "                    fOut.write(f\"{t_key},{preds[i]}\\n\")\n",
        "                    written_keys.add(t_key)\n",
        "\n",
        "            user_tracks = []\n",
        "            user_metadata = []\n",
        "\n",
        "        user_tracks.append(trackID)\n",
        "        user_metadata.append({'trackID': trackID, 'albumID': albumID, 'artistID': artistID, 'genreIDs': genreIDs})\n",
        "        lastUserID = userID\n",
        "\n",
        "    # Handle last user block\n",
        "    if user_tracks:\n",
        "        u_ratings = train_data.get(lastUserID, {})\n",
        "        default_score = user_avg_scores.get(lastUserID, global_avg_score)\n",
        "        if lastUserID not in train_data or not u_ratings:\n",
        "            unseen_users += 1\n",
        "            artist_scores = []\n",
        "            for i, t_data in enumerate(user_metadata):\n",
        "                artist_score = artist_global_avg.get(t_data['artistID'], global_avg_score) if t_data['artistID'] else global_avg_score\n",
        "                weight = 1.2 if artist_score > global_avg_score else 0.8\n",
        "                artist_scores.append(artist_score * weight)\n",
        "            top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "            preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "            cold_start_preds += sum(preds)\n",
        "        else:\n",
        "            X_test = []\n",
        "            for i, t_data in enumerate(user_metadata):\n",
        "                tID = t_data['trackID']\n",
        "                raw_track_score = u_ratings.get(tID, u_ratings.get(f\"track_{tID}\", 0))\n",
        "                raw_album_score = u_ratings.get(t_data['albumID'], 0) if t_data['albumID'] else 0\n",
        "                raw_artist_score = u_ratings.get(t_data['artistID'], 0) if t_data['artistID'] else 0\n",
        "                genre_scores = [u_ratings.get(gid, 0) for gid in t_data['genreIDs']]\n",
        "                genre_rated = [s for s in genre_scores if s > 0]\n",
        "                raw_genre_score = np.mean(genre_rated) if genre_rated else 0\n",
        "                genre_count = len(t_data['genreIDs'])\n",
        "                artist_popularity = artist_global_avg.get(t_data['artistID'], global_avg_score) if t_data['artistID'] else global_avg_score\n",
        "                genre_score_weighted = raw_genre_score * (len(genre_rated) / len(t_data['genreIDs']) if t_data['genreIDs'] else 0)\n",
        "\n",
        "                album_score_missing = 1 if raw_album_score == 0 else 0\n",
        "                artist_score_missing = 1 if raw_artist_score == 0 else 0\n",
        "                genre_score_missing = 1 if not genre_rated else 0\n",
        "                artist_score_weighted = raw_artist_score * (1 - artist_score_missing)\n",
        "                user_variance = user_rating_variance.get(lastUserID, 0)\n",
        "                user_rcount = user_rating_count.get(lastUserID, 0)\n",
        "                artist_score = min(raw_artist_score, 100) if raw_artist_score > 0 else default_score\n",
        "                genre_score = min(raw_genre_score, 100) if raw_genre_score > 0 else default_score\n",
        "\n",
        "                features = [\n",
        "                    artist_score,\n",
        "                    genre_score,\n",
        "                    album_score_missing,\n",
        "                    artist_score_missing,\n",
        "                    genre_score_missing,\n",
        "                    artist_score_weighted,\n",
        "                    user_variance,\n",
        "                    user_rcount,\n",
        "                    genre_count,\n",
        "                    artist_popularity,\n",
        "                    genre_score_weighted\n",
        "                ]\n",
        "                X_test.append(features)\n",
        "\n",
        "            X_test = np.array(X_test)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "            probs = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "            prob_diff = np.max(probs) - np.min(probs)\n",
        "            top3 = np.argsort(-probs)[:3]\n",
        "            preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "            if prob_diff < 0.03:\n",
        "                artist_scores = [X_test[i][0] * (1 - X_test[i][3]) for i in range(len(X_test))]\n",
        "                top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "                preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "                cold_start_preds += sum(preds)\n",
        "\n",
        "        for i, t_data in enumerate(user_metadata):\n",
        "            t_key = f\"{lastUserID}_{t_data['trackID']}\"\n",
        "            if t_key not in written_keys:\n",
        "                fOut.write(f\"{t_key},{preds[i]}\\n\")\n",
        "                written_keys.add(t_key)\n",
        "\n",
        "fOut.close()\n",
        "print(f\"Submission file '{output_file}' written with {len(written_keys)} predictions.\")\n",
        "print(f\"Unseen users in test set: {unseen_users}\")\n",
        "print(f\"Cold-start predictions (positive): {cold_start_preds}\")\n",
        "\n",
        "# Evaluate on ground truth\n",
        "print(\"Evaluating on ground truth...\")\n",
        "y_true = []\n",
        "y_pred = []\n",
        "eval_users = set()\n",
        "prob_dist = []\n",
        "\n",
        "for userID in gt_users:\n",
        "    user_track_keys = [k for k in ground_truth.keys() if k.startswith(userID + '_')]\n",
        "    if not user_track_keys:\n",
        "        print(f\"Warning: User {userID} has no tracks in ground truth. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    u_ratings = train_data.get(userID, {})\n",
        "    default_score = user_avg_scores.get(userID, global_avg_score)\n",
        "    X_test = []\n",
        "\n",
        "    for track_key in user_track_keys:\n",
        "        t_data = test_tracks.get(track_key, {'trackID': track_key.split('_')[1], 'albumID': None, 'artistID': None, 'genreIDs': []})\n",
        "        raw_track_score = u_ratings.get(t_data['trackID'], u_ratings.get(f\"track_{t_data['trackID']}\", 0))\n",
        "        raw_album_score = u_ratings.get(t_data['albumID'], 0) if t_data['albumID'] else 0\n",
        "        raw_artist_score = u_ratings.get(t_data['artistID'], 0) if t_data['artistID'] else 0\n",
        "        genre_scores = [u_ratings.get(gid, 0) for gid in t_data['genreIDs']]\n",
        "        genre_rated = [s for s in genre_scores if s > 0]\n",
        "        raw_genre_score = np.mean(genre_rated) if genre_rated else 0\n",
        "        genre_count = len(t_data['genreIDs'])\n",
        "        artist_popularity = artist_global_avg.get(t_data['artistID'], global_avg_score) if t_data['artistID'] else global_avg_score\n",
        "        genre_score_weighted = raw_genre_score * (len(genre_rated) / len(t_data['genreIDs']) if t_data['genreIDs'] else 0)\n",
        "\n",
        "        album_score_missing = 1 if raw_album_score == 0 else 0\n",
        "        artist_score_missing = 1 if raw_artist_score == 0 else 0\n",
        "        genre_score_missing = 1 if not genre_rated else 0\n",
        "        artist_score_weighted = raw_artist_score * (1 - artist_score_missing)\n",
        "        user_variance = user_rating_variance.get(userID, 0)\n",
        "        user_rcount = user_rating_count.get(userID, 0)\n",
        "        artist_score = min(raw_artist_score, 100) if raw_artist_score > 0 else default_score\n",
        "        genre_score = min(raw_genre_score, 100) if raw_genre_score > 0 else default_score\n",
        "\n",
        "        features = [\n",
        "            artist_score,\n",
        "            genre_score,\n",
        "            album_score_missing,\n",
        "            artist_score_missing,\n",
        "            genre_score_missing,\n",
        "            artist_score_weighted,\n",
        "            user_variance,\n",
        "            user_rcount,\n",
        "            genre_count,\n",
        "            artist_popularity,\n",
        "            genre_score_weighted\n",
        "        ]\n",
        "        X_test.append(features)\n",
        "\n",
        "    X_test = np.array(X_test)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    probs = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
        "    prob_diff = np.max(probs) - np.min(probs)\n",
        "    top3 = np.argsort(-probs)[:3]\n",
        "    preds = [1 if i in top3 else 0 for i in range(len(user_track_keys))]\n",
        "    if prob_diff < 0.03:\n",
        "        artist_scores = [X_test[i][0] * (1 - X_test[i][3]) for i in range(len(X_test))]\n",
        "        top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "        preds = [1 if i in top3 else 0 for i in range(len(user_track_keys))]\n",
        "        cold_start_preds += sum(preds)\n",
        "\n",
        "    y_pred.extend(preds)\n",
        "    y_true.extend([ground_truth[k] for k in user_track_keys])\n",
        "    prob_dist.extend(probs)\n",
        "    eval_users.add(userID)\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='binary')\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(f\"Ground truth accuracy: {accuracy:.4f} over {len(y_true)} samples from {len(eval_users)} users.\")\n",
        "print(f\"Precision@3: {precision:.4f}\")\n",
        "print(f\"Confusion matrix:\\n{cm}\")\n",
        "print(f\"Prediction probability distribution: mean={np.mean(prob_dist):.4f}, std={np.std(prob_dist):.4f}, min={np.min(prob_dist):.4f}, max={np.max(prob_dist):.4f}\")"
      ],
      "metadata": {
        "id": "Y6vq66-K7MMZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is using Decision Tree as the classifier\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "\n",
        "# File paths\n",
        "file_name_test = 'testTrack_hierarchy.txt'\n",
        "file_name_train = 'trainIdx2_matrix.txt'\n",
        "ground_truth_file = 'test2_new.txt'\n",
        "output_file = 'submission_dt_tuned_v1.csv'\n",
        "\n",
        "# Load ground truth\n",
        "print(\"Loading ground truth...\")\n",
        "ground_truth = {}\n",
        "with open(ground_truth_file, 'r') as f:\n",
        "    for line in f:\n",
        "        userID, trackID, label = line.strip().split('|')\n",
        "        ground_truth[f\"{userID}_{trackID}\"] = int(label)\n",
        "gt_users = set(k.split('_')[0] for k in ground_truth.keys())\n",
        "gt_tracks = set(k.split('_')[1] for k in ground_truth.keys())\n",
        "print(f\"Loaded {len(ground_truth)} ground truth labels ({sum(1 for v in ground_truth.values() if v == 1)} positive, {sum(1 for v in ground_truth.values() if v == 0)} negative).\")\n",
        "print(f\"Unique users in ground truth: {len(gt_users)}\")\n",
        "\n",
        "# Load test hierarchy\n",
        "print(\"Loading test hierarchy for trackIDs...\")\n",
        "test_tracks = {}\n",
        "with open(file_name_test, 'r') as fTest:\n",
        "    for line in fTest:\n",
        "        parts = line.strip().split('|')\n",
        "        userID = parts[0]\n",
        "        trackID = parts[1]\n",
        "        albumID = parts[2] if parts[2] != \"None\" else None\n",
        "        artistID = parts[3] if len(parts) > 3 and parts[3] != \"None\" else None\n",
        "        genreIDs = parts[4:] if len(parts) > 4 else []\n",
        "        test_tracks[f\"{userID}_{trackID}\"] = {\n",
        "            'trackID': trackID,\n",
        "            'albumID': albumID,\n",
        "            'artistID': artistID,\n",
        "            'genreIDs': genreIDs\n",
        "        }\n",
        "test_track_ids = set(t['trackID'] for t in test_tracks.values())\n",
        "print(f\"Loaded {len(test_tracks)} user-track pairs.\")\n",
        "print(f\"Ground truth tracks in test hierarchy: {len(gt_tracks & test_track_ids)}/{len(gt_tracks)}\")\n",
        "\n",
        "# Load training data\n",
        "print(\"Reading training data...\")\n",
        "train_data = {}\n",
        "user_ratings = {}\n",
        "all_scores = []\n",
        "artist_global_scores = {}\n",
        "\n",
        "with open(file_name_train, 'r') as fTrain:\n",
        "    for line in fTrain:\n",
        "        userID, itemID, score = line.strip().split('|')\n",
        "        score = int(score)\n",
        "        if userID not in train_data:\n",
        "            train_data[userID] = {}\n",
        "        train_data[userID][itemID] = score\n",
        "        all_scores.append(score)\n",
        "        if userID not in user_ratings:\n",
        "            user_ratings[userID] = []\n",
        "        user_ratings[userID].append(score)\n",
        "        if itemID.startswith('artist_'):\n",
        "            if itemID not in artist_global_scores:\n",
        "                artist_global_scores[itemID] = []\n",
        "            artist_global_scores[itemID].append(score)\n",
        "\n",
        "global_avg_score = np.mean(all_scores) if all_scores else 0\n",
        "user_avg_scores = {\n",
        "    uid: np.mean(scores) if scores else global_avg_score for uid, scores in user_ratings.items()\n",
        "}\n",
        "user_rating_count = {\n",
        "    uid: len(scores) for uid, scores in user_ratings.items()\n",
        "}\n",
        "user_rating_variance = {\n",
        "    uid: np.std(scores) if scores else 0 for uid, scores in user_ratings.items()\n",
        "}\n",
        "# Log-transform and cap user_rating_count\n",
        "user_rating_count = {uid: min(np.log1p(count), 5.0) for uid, count in user_rating_count.items()}\n",
        "# Global artist averages for cold-start\n",
        "artist_global_avg = {\n",
        "    aid: np.mean(scores) if scores else global_avg_score for aid, scores in artist_global_scores.items()\n",
        "}\n",
        "print(f\"Training data loaded. Global average score: {global_avg_score:.2f}\")\n",
        "print(f\"User variance mean: {np.mean(list(user_rating_variance.values())):.2f}, std: {np.std(list(user_rating_variance.values())):.2f}\")\n",
        "print(f\"User rating count mean: {np.mean(list(user_rating_count.values())):.2f}, std: {np.std(list(user_rating_count.values())):.2f}\")\n",
        "user_rating_coverage = {uid: sum(1 for tid in gt_tracks if tid in train_data.get(uid, {})) for uid in gt_users}\n",
        "print(f\"Users with ratings for ground truth tracks: {sum(1 for v in user_rating_coverage.values() if v > 0)}/{len(gt_users)}\")\n",
        "\n",
        "# Debug track IDs\n",
        "sample_train_items = []\n",
        "for uid in list(train_data.keys())[:5]:\n",
        "    sample_train_items.extend(list(train_data[uid].keys())[:5])\n",
        "print(f\"Sample training item IDs: {sample_train_items[:10]}\")\n",
        "print(f\"Sample ground truth track IDs: {list(gt_tracks)[:5]}\")\n",
        "\n",
        "# Prepare training data\n",
        "print(\"Preparing training data for DT...\")\n",
        "X_train = []\n",
        "y_train = []\n",
        "users_processed = set()\n",
        "feature_stats = {\n",
        "    'artist': [], 'genre': [], 'album_score_missing': [], 'artist_score_missing': [],\n",
        "    'genre_score_missing': [], 'artist_score_weighted': [], 'user_variance': [], 'user_rating_count': []\n",
        "}\n",
        "raw_counts = {'track': 0, 'album': 0, 'artist': 0, 'genre': 0}\n",
        "label_ratings = {\n",
        "    'positive': {'artist': [], 'genre': [], 'artist_score_weighted': []},\n",
        "    'negative': {'artist': [], 'genre': [], 'artist_score_weighted': []}\n",
        "}\n",
        "track_label_counts = {tid: {'pos': 0, 'neg': 0} for tid in gt_tracks}\n",
        "track_rating_debug = []\n",
        "\n",
        "for userID in gt_users:\n",
        "    u_ratings = train_data.get(userID, {})\n",
        "    user_track_keys = [k for k in ground_truth.keys() if k.startswith(userID + '_')]\n",
        "    if not user_track_keys:\n",
        "        print(f\"Warning: User {userID} has no tracks in ground truth. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    for track_key in user_track_keys:\n",
        "        trackID = track_key.split('_')[1]\n",
        "        label = ground_truth[track_key]\n",
        "        track_label_counts[trackID]['pos' if label == 1 else 'neg'] += 1\n",
        "\n",
        "        # Extract features\n",
        "        t_data = test_tracks.get(track_key, {'trackID': trackID, 'albumID': None, 'artistID': None, 'genreIDs': []})\n",
        "        # Try raw trackID and prefixed versions\n",
        "        raw_track_score = u_ratings.get(t_data['trackID'], u_ratings.get(f\"track_{t_data['trackID']}\", 0))\n",
        "        raw_album_score = u_ratings.get(t_data['albumID'], 0) if t_data['albumID'] else 0\n",
        "        raw_artist_score = u_ratings.get(t_data['artistID'], 0) if t_data['artistID'] else 0\n",
        "        genre_scores = [u_ratings.get(gid, 0) for gid in t_data['genreIDs']]\n",
        "        genre_rated = [s for s in genre_scores if s > 0]\n",
        "        raw_genre_score = np.mean(genre_rated) if genre_rated else 0\n",
        "\n",
        "        # Debug track ratings\n",
        "        track_rating_debug.append(raw_track_score)\n",
        "        if raw_track_score > 0:\n",
        "            raw_counts['track'] += 1\n",
        "        if raw_album_score > 0:\n",
        "            raw_counts['album'] += 1\n",
        "        if raw_artist_score > 0:\n",
        "            raw_counts['artist'] += 1\n",
        "        if raw_genre_score > 0:\n",
        "            raw_counts['genre'] += 1\n",
        "\n",
        "        album_score_missing = 1 if raw_album_score == 0 else 0\n",
        "        artist_score_missing = 1 if raw_artist_score == 0 else 0\n",
        "        genre_score_missing = 1 if not genre_rated else 0\n",
        "        artist_score_weighted = raw_artist_score * (1 - artist_score_missing)\n",
        "        user_variance = user_rating_variance.get(userID, 0)\n",
        "        user_rcount = user_rating_count.get(userID, 0)\n",
        "        default_score = user_avg_scores.get(userID, global_avg_score)\n",
        "        artist_score = min(raw_artist_score, 100) if raw_artist_score > 0 else default_score\n",
        "        genre_score = min(raw_genre_score, 100) if raw_genre_score > 0 else default_score\n",
        "\n",
        "        features = [\n",
        "            artist_score,\n",
        "            genre_score,\n",
        "            album_score_missing,\n",
        "            artist_score_missing,\n",
        "            genre_score_missing,\n",
        "            artist_score_weighted,\n",
        "            user_variance,\n",
        "            user_rcount\n",
        "        ]\n",
        "        X_train.append(features)\n",
        "        y_train.append(label)\n",
        "\n",
        "        # Track feature statistics and label ratings\n",
        "        feature_stats['artist'].append(artist_score)\n",
        "        feature_stats['genre'].append(genre_score)\n",
        "        feature_stats['album_score_missing'].append(album_score_missing)\n",
        "        feature_stats['artist_score_missing'].append(artist_score_missing)\n",
        "        feature_stats['genre_score_missing'].append(genre_score_missing)\n",
        "        feature_stats['artist_score_weighted'].append(artist_score_weighted)\n",
        "        feature_stats['user_variance'].append(user_variance)\n",
        "        feature_stats['user_rating_count'].append(user_rcount)\n",
        "        label_ratings['positive' if label == 1 else 'negative']['artist'].append(artist_score)\n",
        "        label_ratings['positive' if label == 1 else 'negative']['genre'].append(genre_score)\n",
        "        label_ratings['positive' if label == 1 else 'negative']['artist_score_weighted'].append(artist_score_weighted)\n",
        "\n",
        "    users_processed.add(userID)\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "print(f\"Prepared {len(X_train)} training samples from {len(users_processed)} users.\")\n",
        "print(\"Feature statistics (non-zero counts):\")\n",
        "for fname, fvals in feature_stats.items():\n",
        "    if fname in ['album_score_missing', 'artist_score_missing', 'genre_score_missing']:\n",
        "        non_zero = sum(1 for v in fvals if v != 0)\n",
        "    else:\n",
        "        non_zero = sum(1 for v in fvals if v != global_avg_score and v != 0)\n",
        "    print(f\"  {fname}: {non_zero}/{len(fvals)} non-zero values\")\n",
        "print(\"Raw rating counts (before defaulting):\")\n",
        "for fname, count in raw_counts.items():\n",
        "    print(f\"  {fname}: {count}/{len(X_train)} non-zero values\")\n",
        "print(f\"Track rating debug: {sum(1 for v in track_rating_debug if v > 0)}/{len(track_rating_debug)} non-zero raw_track_score\")\n",
        "for ftype in ['artist', 'genre', 'artist_score_weighted']:\n",
        "    print(f\"Average {ftype}_score for positive labels: {np.mean(label_ratings['positive'][ftype]):.2f}\")\n",
        "    print(f\"Average {ftype}_score for negative labels: {np.mean(label_ratings['negative'][ftype]):.2f}\")\n",
        "    print(f\"Std {ftype}_score for positive labels: {np.std(label_ratings['positive'][ftype]):.2f}\")\n",
        "    print(f\"Std {ftype}_score for negative labels: {np.std(label_ratings['negative'][ftype]):.2f}\")\n",
        "mixed_label_tracks = sum(1 for v in track_label_counts.values() if v['pos'] > 0 and v['neg'] > 0)\n",
        "print(f\"Tracks with mixed labels: {mixed_label_tracks}/{len(gt_tracks)}\")\n",
        "# Feature correlations\n",
        "feature_names = ['artist', 'genre', 'album_score_missing', 'artist_score_missing', 'genre_score_missing', 'artist_score_weighted', 'user_variance', 'user_rating_count']\n",
        "corr_matrix = np.corrcoef(X_train.T)\n",
        "print(\"Feature correlations:\")\n",
        "for i, fname in enumerate(feature_names):\n",
        "    for j in range(i+1, len(feature_names)):\n",
        "        if abs(corr_matrix[i, j]) > 0.5:\n",
        "            print(f\"  {fname} vs {feature_names[j]}: {corr_matrix[i, j]:.2f}\")\n",
        "\n",
        "# Train Decision Tree model with GridSearchCV\n",
        "print(\"Training Decision Tree model with hyperparameter tuning...\")\n",
        "scaler = RobustScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "dt_model = DecisionTreeClassifier(random_state=42, class_weight='balanced')\n",
        "param_grid = {\n",
        "    'max_depth': [5, 10, 15, 20],\n",
        "    'min_samples_split': [10, 20, 30],\n",
        "    'min_samples_leaf': [5, 10, 15]\n",
        "}\n",
        "grid_search = GridSearchCV(dt_model, param_grid, cv=5, scoring='precision', n_jobs=-1)\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "dt_model = grid_search.best_estimator_\n",
        "cv_scores = cross_val_score(dt_model, X_train_scaled, y_train, cv=5, scoring='accuracy')\n",
        "cv_precision_scores = cross_val_score(dt_model, X_train_scaled, y_train, cv=5, scoring='precision')\n",
        "print(\"Model training completed.\")\n",
        "print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
        "print(\"Feature importances:\", dict(zip(feature_names, dt_model.feature_importances_)))\n",
        "print(\"Feature means after scaling:\", np.mean(X_train_scaled, axis=0))\n",
        "print(\"Feature stds after scaling:\", np.std(X_train_scaled, axis=0))\n",
        "print(f\"Cross-validation accuracy: {np.mean(cv_scores):.4f} ± {np.std(cv_scores):.4f}\")\n",
        "print(f\"Cross-validation Precision@3: {np.mean(cv_precision_scores):.4f} ± {np.std(cv_precision_scores):.4f}\")\n",
        "\n",
        "# Output predictions\n",
        "fOut = open(output_file, 'w')\n",
        "fOut.write(\"TrackID,Predictor\\n\")\n",
        "written_keys = set()\n",
        "unseen_users = 0\n",
        "cold_start_preds = 0\n",
        "\n",
        "print(\"Processing test data...\")\n",
        "with open(file_name_test, 'r') as fTest:\n",
        "    lastUserID = None\n",
        "    user_tracks = []\n",
        "    user_metadata = []\n",
        "\n",
        "    for line in fTest:\n",
        "        parts = line.strip().split('|')\n",
        "        userID = parts[0]\n",
        "        trackID = parts[1]\n",
        "        albumID = parts[2] if parts[2] != \"None\" else None\n",
        "        artistID = parts[3] if len(parts) > 3 and parts[3] != \"None\" else None\n",
        "        genreIDs = parts[4:] if len(parts) > 4 else []\n",
        "\n",
        "        if userID != lastUserID and lastUserID is not None and user_tracks:\n",
        "            u_ratings = train_data.get(lastUserID, {})\n",
        "            default_score = user_avg_scores.get(lastUserID, global_avg_score)\n",
        "            if lastUserID not in train_data or not u_ratings:\n",
        "                unseen_users += 1\n",
        "                # Fallback to weighted global artist_score\n",
        "                artist_scores = []\n",
        "                for i, t_data in enumerate(user_metadata):\n",
        "                    artist_score = artist_global_avg.get(t_data['artistID'], global_avg_score) if t_data['artistID'] else global_avg_score\n",
        "                    weight = 1.2 if artist_score > global_avg_score else 0.8\n",
        "                    artist_scores.append(artist_score * weight)\n",
        "                top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "                preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "                cold_start_preds += sum(preds)\n",
        "            else:\n",
        "                X_test = []\n",
        "                for i, t_data in enumerate(user_metadata):\n",
        "                    tID = t_data['trackID']\n",
        "                    raw_track_score = u_ratings.get(tID, u_ratings.get(f\"track_{tID}\", 0))\n",
        "                    raw_album_score = u_ratings.get(t_data['albumID'], 0) if t_data['albumID'] else 0\n",
        "                    raw_artist_score = u_ratings.get(t_data['artistID'], 0) if t_data['artistID'] else 0\n",
        "                    genre_scores = [u_ratings.get(gid, 0) for gid in t_data['genreIDs']]\n",
        "                    genre_rated = [s for s in genre_scores if s > 0]\n",
        "                    raw_genre_score = np.mean(genre_rated) if genre_rated else 0\n",
        "\n",
        "                    album_score_missing = 1 if raw_album_score == 0 else 0\n",
        "                    artist_score_missing = 1 if raw_artist_score == 0 else 0\n",
        "                    genre_score_missing = 1 if not genre_rated else 0\n",
        "                    artist_score_weighted = raw_artist_score * (1 - artist_score_missing)\n",
        "                    user_variance = user_rating_variance.get(lastUserID, 0)\n",
        "                    user_rcount = user_rating_count.get(lastUserID, 0)\n",
        "                    artist_score = min(raw_artist_score, 100) if raw_artist_score > 0 else default_score\n",
        "                    genre_score = min(raw_genre_score, 100) if raw_genre_score > 0 else default_score\n",
        "\n",
        "                    features = [\n",
        "                        artist_score,\n",
        "                        genre_score,\n",
        "                        album_score_missing,\n",
        "                        artist_score_missing,\n",
        "                        genre_score_missing,\n",
        "                        artist_score_weighted,\n",
        "                        user_variance,\n",
        "                        user_rcount\n",
        "                    ]\n",
        "                    X_test.append(features)\n",
        "\n",
        "                X_test = np.array(X_test)\n",
        "                X_test_scaled = scaler.transform(X_test)\n",
        "                probs = dt_model.predict_proba(X_test_scaled)[:, 1]\n",
        "                prob_diff = np.max(probs) - np.min(probs)\n",
        "                top3 = np.argsort(-probs)[:3 if prob_diff > 0.25 else 2]\n",
        "                preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "                if prob_diff < 0.1:  # Fallback for low confidence\n",
        "                    artist_scores = [X_test[i][0] * (1 - X_test[i][3]) for i in range(len(X_test))]\n",
        "                    top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "                    preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "                    cold_start_preds += sum(preds)\n",
        "\n",
        "            for i, t_data in enumerate(user_metadata):\n",
        "                t_key = f\"{lastUserID}_{t_data['trackID']}\"\n",
        "                if t_key not in written_keys:\n",
        "                    fOut.write(f\"{t_key},{preds[i]}\\n\")\n",
        "                    written_keys.add(t_key)\n",
        "\n",
        "            user_tracks = []\n",
        "            user_metadata = []\n",
        "\n",
        "        user_tracks.append(trackID)\n",
        "        user_metadata.append({'trackID': trackID, 'albumID': albumID, 'artistID': artistID, 'genreIDs': genreIDs})\n",
        "        lastUserID = userID\n",
        "\n",
        "    # Handle last user block\n",
        "    if user_tracks:\n",
        "        u_ratings = train_data.get(lastUserID, {})\n",
        "        default_score = user_avg_scores.get(lastUserID, global_avg_score)\n",
        "        if lastUserID not in train_data or not u_ratings:\n",
        "            unseen_users += 1\n",
        "            artist_scores = []\n",
        "            for i, t_data in enumerate(user_metadata):\n",
        "                artist_score = artist_global_avg.get(t_data['artistID'], global_avg_score) if t_data['artistID'] else global_avg_score\n",
        "                weight = 1.2 if artist_score > global_avg_score else 0.8\n",
        "                artist_scores.append(artist_score * weight)\n",
        "            top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "            preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "            cold_start_preds += sum(preds)\n",
        "        else:\n",
        "            X_test = []\n",
        "            for i, t_data in enumerate(user_metadata):\n",
        "                tID = t_data['trackID']\n",
        "                raw_track_score = u_ratings.get(tID, u_ratings.get(f\"track_{tID}\", 0))\n",
        "                raw_album_score = u_ratings.get(t_data['albumID'], 0) if t_data['albumID'] else 0\n",
        "                raw_artist_score = u_ratings.get(t_data['artistID'], 0) if t_data['artistID'] else 0\n",
        "                genre_scores = [u_ratings.get(gid, 0) for gid in t_data['genreIDs']]\n",
        "                genre_rated = [s for s in genre_scores if s > 0]\n",
        "                raw_genre_score = np.mean(genre_rated) if genre_rated else 0\n",
        "\n",
        "                album_score_missing = 1 if raw_album_score == 0 else 0\n",
        "                artist_score_missing = 1 if raw_artist_score == 0 else 0\n",
        "                genre_score_missing = 1 if not genre_rated else 0\n",
        "                artist_score_weighted = raw_artist_score * (1 - artist_score_missing)\n",
        "                user_variance = user_rating_variance.get(lastUserID, 0)\n",
        "                user_rcount = user_rating_count.get(lastUserID, 0)\n",
        "                artist_score = min(raw_artist_score, 100) if raw_artist_score > 0 else default_score\n",
        "                genre_score = min(raw_genre_score, 100) if raw_genre_score > 0 else default_score\n",
        "\n",
        "                features = [\n",
        "                    artist_score,\n",
        "                    genre_score,\n",
        "                    album_score_missing,\n",
        "                    artist_score_missing,\n",
        "                    genre_score_missing,\n",
        "                    artist_score_weighted,\n",
        "                    user_variance,\n",
        "                    user_rcount\n",
        "                ]\n",
        "                X_test.append(features)\n",
        "\n",
        "            X_test = np.array(X_test)\n",
        "            X_test_scaled = scaler.transform(X_test)\n",
        "            probs = dt_model.predict_proba(X_test_scaled)[:, 1]\n",
        "            prob_diff = np.max(probs) - np.min(probs)\n",
        "            top3 = np.argsort(-probs)[:3 if prob_diff > 0.25 else 2]\n",
        "            preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "            if prob_diff < 0.1:\n",
        "                artist_scores = [X_test[i][0] * (1 - X_test[i][3]) for i in range(len(X_test))]\n",
        "                top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "                preds = [1 if i in top3 else 0 for i in range(len(user_tracks))]\n",
        "                cold_start_preds += sum(preds)\n",
        "\n",
        "        for i, t_data in enumerate(user_metadata):\n",
        "            t_key = f\"{lastUserID}_{t_data['trackID']}\"\n",
        "            if t_key not in written_keys:\n",
        "                fOut.write(f\"{t_key},{preds[i]}\\n\")\n",
        "                written_keys.add(t_key)\n",
        "\n",
        "fOut.close()\n",
        "print(f\"Submission file '{output_file}' written with {len(written_keys)} predictions.\")\n",
        "print(f\"Unseen users in test set: {unseen_users}\")\n",
        "print(f\"Cold-start predictions (positive): {cold_start_preds}\")\n",
        "\n",
        "# Evaluate on ground truth\n",
        "print(\"Evaluating on ground truth...\")\n",
        "y_true = []\n",
        "y_pred = []\n",
        "eval_users = set()\n",
        "prob_dist = []\n",
        "\n",
        "for userID in gt_users:\n",
        "    user_track_keys = [k for k in ground_truth.keys() if k.startswith(userID + '_')]\n",
        "    if not user_track_keys:\n",
        "        print(f\"Warning: User {userID} has no tracks in ground truth. Skipping.\")\n",
        "        continue\n",
        "\n",
        "    u_ratings = train_data.get(userID, {})\n",
        "    default_score = user_avg_scores.get(userID, global_avg_score)\n",
        "    X_test = []\n",
        "\n",
        "    for track_key in user_track_keys:\n",
        "        t_data = test_tracks.get(track_key, {'trackID': track_key.split('_')[1], 'albumID': None, 'artistID': None, 'genreIDs': []})\n",
        "        raw_track_score = u_ratings.get(t_data['trackID'], u_ratings.get(f\"track_{t_data['trackID']}\", 0))\n",
        "        raw_album_score = u_ratings.get(t_data['albumID'], 0) if t_data['albumID'] else 0\n",
        "        raw_artist_score = u_ratings.get(t_data['artistID'], 0) if t_data['artistID'] else 0\n",
        "        genre_scores = [u_ratings.get(gid, 0) for gid in t_data['genreIDs']]\n",
        "        genre_rated = [s for s in genre_scores if s > 0]\n",
        "        raw_genre_score = np.mean(genre_rated) if genre_rated else 0\n",
        "\n",
        "        album_score_missing = 1 if raw_album_score == 0 else 0\n",
        "        artist_score_missing = 1 if raw_artist_score == 0 else 0\n",
        "        genre_score_missing = 1 if not genre_rated else 0\n",
        "        artist_score_weighted = raw_artist_score * (1 - artist_score_missing)\n",
        "        user_variance = user_rating_variance.get(userID, 0)\n",
        "        user_rcount = user_rating_count.get(userID, 0)\n",
        "        artist_score = min(raw_artist_score, 100) if raw_artist_score > 0 else default_score\n",
        "        genre_score = min(raw_genre_score, 100) if raw_genre_score > 0 else default_score\n",
        "\n",
        "        features = [\n",
        "            artist_score,\n",
        "            genre_score,\n",
        "            album_score_missing,\n",
        "            artist_score_missing,\n",
        "            genre_score_missing,\n",
        "            artist_score_weighted,\n",
        "            user_variance,\n",
        "            user_rcount\n",
        "        ]\n",
        "        X_test.append(features)\n",
        "\n",
        "    X_test = np.array(X_test)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    probs = dt_model.predict_proba(X_test_scaled)[:, 1]\n",
        "    prob_diff = np.max(probs) - np.min(probs)\n",
        "    top3 = np.argsort(-probs)[:3 if prob_diff > 0.25 else 2]\n",
        "    preds = [1 if i in top3 else 0 for i in range(len(user_track_keys))]\n",
        "    if prob_diff < 0.1:\n",
        "        artist_scores = [X_test[i][0] * (1 - X_test[i][3]) for i in range(len(X_test))]\n",
        "        top3 = np.argsort(-np.array(artist_scores))[:3]\n",
        "        preds = [1 if i in top3 else 0 for i in range(len(user_track_keys))]\n",
        "        cold_start_preds += sum(preds)\n",
        "\n",
        "    y_pred.extend(preds)\n",
        "    y_true.extend([ground_truth[k] for k in user_track_keys])\n",
        "    prob_dist.extend(probs)\n",
        "    eval_users.add(userID)\n",
        "\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred, average='binary')\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(f\"Ground truth accuracy: {accuracy:.4f} over {len(y_true)} samples from {len(eval_users)} users.\")\n",
        "print(f\"Precision@3: {precision:.4f}\")\n",
        "print(f\"Confusion matrix:\\n{cm}\")\n",
        "print(f\"Prediction probability distribution: mean={np.mean(prob_dist):.4f}, std={np.std(prob_dist):.4f}, min={np.min(prob_dist):.4f}, max={np.max(prob_dist):.4f}\")"
      ],
      "metadata": {
        "id": "e_VorMJJ7ljT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This code is using a Gradient Boost Classifier with proper hyperparameter tuning\n",
        "import os\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    StratifiedKFold,\n",
        "    RandomizedSearchCV\n",
        ")\n",
        "\n",
        "# File paths\n",
        "file_name_test    = 'testTrack_hierarchy.txt'\n",
        "file_name_train   = 'trainIdx2_matrix.txt'\n",
        "ground_truth_file = 'test2_new.txt'\n",
        "output_file       = 'submission_gb_v5.csv'\n",
        "\n",
        "# 1. Load ground truth\n",
        "print(\"Loading ground truth...\")\n",
        "ground_truth = {}\n",
        "with open(ground_truth_file, 'r') as f:\n",
        "    for line in f:\n",
        "        u, t, l = line.strip().split('|')\n",
        "        ground_truth[f\"{u}_{t}\"] = int(l)\n",
        "gt_users  = set(k.split('_')[0] for k in ground_truth)\n",
        "gt_tracks = set(k.split('_')[1] for k in ground_truth)\n",
        "print(f\"Loaded {len(ground_truth)} labels ({sum(ground_truth.values())} positives).\")\n",
        "\n",
        "# 2. Load test hierarchy\n",
        "print(\"Loading test hierarchy...\")\n",
        "test_tracks = {}\n",
        "with open(file_name_test, 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split('|')\n",
        "        u, t = parts[0], parts[1]\n",
        "        alb = parts[2] if parts[2] != \"None\" else None\n",
        "        art = parts[3] if len(parts)>3 and parts[3]!=\"None\" else None\n",
        "        gens= parts[4:] if len(parts)>4 else []\n",
        "        test_tracks[f\"{u}_{t}\"] = {\n",
        "            'trackID':  t,\n",
        "            'albumID':  alb,\n",
        "            'artistID': art,\n",
        "            'genreIDs': gens\n",
        "        }\n",
        "print(f\"Loaded {len(test_tracks)} test pairs.\")\n",
        "\n",
        "# 3. Load training data\n",
        "print(\"Reading training data...\")\n",
        "train_data     = {}\n",
        "user_ratings   = {}\n",
        "artist_scores  = {}\n",
        "genre_scores   = {}\n",
        "user_genre_rats= {}\n",
        "all_scores     = []\n",
        "\n",
        "with open(file_name_train, 'r') as f:\n",
        "    for line in f:\n",
        "        u, i, s = line.strip().split('|')\n",
        "        s = int(s)\n",
        "        train_data.setdefault(u, {})[i] = s\n",
        "        all_scores.append(s)\n",
        "        user_ratings.setdefault(u, []).append(s)\n",
        "        if i.startswith('artist_'):\n",
        "            artist_scores.setdefault(i, []).append(s)\n",
        "        if i.startswith('genre_'):\n",
        "            genre_scores.setdefault(i, []).append(s)\n",
        "            user_genre_rats.setdefault(u, []).append(s)\n",
        "\n",
        "# 4. Precompute stats\n",
        "global_avg     = np.mean(all_scores) if all_scores else 0.0\n",
        "user_avg       = {u:np.mean(v) for u,v in user_ratings.items()}\n",
        "user_var       = {u:np.std(v)  for u,v in user_ratings.items()}\n",
        "user_cnt       = {u:np.log1p(len(v)) for u,v in user_ratings.items()}\n",
        "artist_avg     = {a:np.mean(v) for a,v in artist_scores.items()}\n",
        "genre_avg      = {g:np.mean(v) for g,v in genre_scores.items()}\n",
        "user_genre_aff = {u:np.mean(v) for u,v in user_genre_rats.items()}\n",
        "\n",
        "# 5. Feature engineering helper\n",
        "def compute_features(u, td):\n",
        "    u_r = train_data.get(u, {})\n",
        "    default = user_avg.get(u, global_avg)\n",
        "\n",
        "    raw_track  = u_r.get(td['trackID'], u_r.get(f\"track_{td['trackID']}\", 0))\n",
        "    raw_album  = u_r.get(td['albumID'], 0) if td['albumID'] else 0\n",
        "    raw_artist = u_r.get(td['artistID'], 0) if td['artistID'] else 0\n",
        "\n",
        "    gs_list = [u_r.get(g,0) for g in td['genreIDs']]\n",
        "    gs_vals = [s for s in gs_list if s>0]\n",
        "    raw_genre = np.mean(gs_vals) if gs_vals else 0\n",
        "\n",
        "    gc     = len(td['genreIDs'])\n",
        "    apr    = artist_avg.get(f\"artist_{td['artistID']}\", global_avg) if td['artistID'] else global_avg\n",
        "    gw     = raw_genre * (len(gs_vals)/gc if gc else 0)\n",
        "    ugaff  = user_genre_aff.get(u, global_avg)\n",
        "\n",
        "    asm = 1 if raw_artist==0 else 0\n",
        "    gsm = 1 if not gs_vals else 0\n",
        "    asw = raw_artist * (1-asm)\n",
        "    uv  = user_var.get(u,0.0)\n",
        "    uc  = user_cnt.get(u,0.0)\n",
        "    a_s = min(raw_artist,100) if raw_artist>0 else user_avg.get(u,global_avg)\n",
        "    g_s = min(raw_genre,100)  if raw_genre>0  else user_avg.get(u,global_avg)\n",
        "\n",
        "    album_score = min(raw_album,100) if raw_album>0 else default\n",
        "    track_score = min(raw_track,100) if raw_track>0 else default\n",
        "    has_album   = 1 if td['albumID']  else 0\n",
        "    has_artist  = 1 if td['artistID'] else 0\n",
        "\n",
        "    return [\n",
        "        a_s, g_s, asm, gsm, asw, uv, uc, gc, apr, gw, ugaff,\n",
        "        album_score, track_score, has_album, has_artist\n",
        "    ]\n",
        "\n",
        "# 6. Build train matrix\n",
        "print(\"Building training matrix...\")\n",
        "X, y = [], []\n",
        "for key, lbl in ground_truth.items():\n",
        "    u, t = key.split('_')\n",
        "    td = test_tracks.get(key, {'trackID':t,'albumID':None,'artistID':None,'genreIDs':[]})\n",
        "    X.append(compute_features(u, td))\n",
        "    y.append(lbl)\n",
        "X = np.array(X);  y = np.array(y)\n",
        "\n",
        "# 7. Split + scale\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X, y, test_size=0.15, stratify=y, random_state=42\n",
        ")\n",
        "scaler  = RobustScaler()\n",
        "X_tr_s  = scaler.fit_transform(X_tr)\n",
        "X_val_s = scaler.transform(X_val)\n",
        "\n",
        "# 8. Hyperparameter tuning (no early stopping here)\n",
        "print(\"Starting hyperparameter tuning...\")\n",
        "param_dist = {\n",
        "    'n_estimators':    [100,200,300,400],\n",
        "    'max_depth':       [3,5,7,10],\n",
        "    'learning_rate':   [0.01,0.05,0.1,0.2],\n",
        "    'subsample':       [0.6,0.8,1.0],\n",
        "    'colsample_bytree':[0.6,0.8,1.0],\n",
        "    'scale_pos_weight':[1,2,3]\n",
        "}\n",
        "cv     = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "xgb    = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "search = RandomizedSearchCV(\n",
        "    xgb, param_dist, n_iter=30, scoring='accuracy',\n",
        "    cv=cv, verbose=1, n_jobs=1, random_state=42\n",
        ")\n",
        "# **Removed eval_set & early_stopping_rounds here**\n",
        "search.fit(X_tr_s, y_tr)\n",
        "best_params = search.best_params_\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "\n",
        "# 9. Refit on training split and evaluate on validation\n",
        "best_model = XGBClassifier(**best_params, use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
        "best_model.fit(X_tr_s, y_tr)   # simple fit, no early stopping\n",
        "\n",
        "# Evaluate on held‑out validation set\n",
        "y_pred_val = best_model.predict(X_val_s)\n",
        "print(\"Validation Accuracy :\", accuracy_score(y_val, y_pred_val))\n",
        "print(\"Validation Precision:\", precision_score(y_val, y_pred_val))\n",
        "\n",
        "\n",
        "# 10. Retrain on all data\n",
        "print(\"Retraining on full data...\")\n",
        "X_all_s = scaler.fit_transform(X)\n",
        "best_model.fit(X_all_s, y, verbose=False)\n",
        "\n",
        "# 11. Generate submission\n",
        "print(\"Generating submission...\")\n",
        "with open(output_file, 'w') as fout:\n",
        "    fout.write(\"TrackID,Predictor\\n\")\n",
        "    last_u = None\n",
        "    block  = []\n",
        "    for line in open(file_name_test):\n",
        "        parts = line.strip().split('|')\n",
        "        u, t = parts[0], parts[1]\n",
        "        key   = f\"{u}_{t}\"\n",
        "        if last_u is None: last_u = u\n",
        "        if u != last_u:\n",
        "            # write previous user\n",
        "            Xb = np.array([compute_features(last_u, test_tracks[k]) for k in block])\n",
        "            Xb_s = scaler.transform(Xb)\n",
        "            probs = best_model.predict_proba(Xb_s)[:,1]\n",
        "            top3  = set(np.argsort(-probs)[:3])\n",
        "            for idx,k in enumerate(block):\n",
        "                fout.write(f\"{k},{1 if idx in top3 else 0}\\n\")\n",
        "            block = []\n",
        "            last_u = u\n",
        "        block.append(key)\n",
        "    # last user\n",
        "    if block:\n",
        "        Xb = np.array([compute_features(last_u, test_tracks[k]) for k in block])\n",
        "        Xb_s = scaler.transform(Xb)\n",
        "        probs = best_model.predict_proba(Xb_s)[:,1]\n",
        "        top3  = set(np.argsort(-probs)[:3])\n",
        "        for idx,k in enumerate(block):\n",
        "            fout.write(f\"{k},{1 if idx in top3 else 0}\\n\")\n",
        "\n",
        "print(f\"Submission '{output_file}' written.\")"
      ],
      "metadata": {
        "id": "e7VW7w1m72Vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56751fde-819f-42df-b569-ed585784858a"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading ground truth...\n",
            "Loaded 6000 labels (3000 positives).\n",
            "Loading test hierarchy...\n",
            "Loaded 120000 test pairs.\n",
            "Reading training data...\n",
            "Building training matrix...\n",
            "Starting hyperparameter tuning...\n",
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:12] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:13] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:14] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:15] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:18] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:18] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:18] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:19] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:20] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:21] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:22] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:23] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:24] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:25] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:26] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:27] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:28] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:30] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:31] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:32] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:33] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:34] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:35] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:36] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:37] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:38] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:39] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:40] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:43] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:44] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:45] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:46] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:47] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:48] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:49] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:50] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:51] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:52] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:54] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:55] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:56] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:57] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:58] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:40:59] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:00] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:02] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:03] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:04] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:05] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:07] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:08] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:09] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'subsample': 1.0, 'scale_pos_weight': 1, 'n_estimators': 300, 'max_depth': 3, 'learning_rate': 0.01, 'colsample_bytree': 1.0}\n",
            "Validation Accuracy : 0.8455555555555555\n",
            "Validation Precision: 0.8956743002544529\n",
            "Retraining on full data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [21:41:10] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating submission...\n",
            "Submission 'submission_gb_v5.csv' written.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    StratifiedKFold,\n",
        "    RandomizedSearchCV\n",
        ")\n",
        "\n",
        "# File paths\n",
        "file_name_test    = 'testTrack_hierarchy.txt'\n",
        "file_name_train   = 'trainIdx2_matrix.txt'\n",
        "ground_truth_file = 'test2_new.txt'\n",
        "output_file       = 'submission_lr_v5.csv'\n",
        "\n",
        "# 1. Load ground truth\n",
        "print(\"Loading ground truth...\")\n",
        "ground_truth = {}\n",
        "with open(ground_truth_file, 'r') as f:\n",
        "    for line in f:\n",
        "        u, t, l = line.strip().split('|')\n",
        "        ground_truth[f\"{u}_{t}\"] = int(l)\n",
        "gt_users  = set(k.split('_')[0] for k in ground_truth)\n",
        "gt_tracks = set(k.split('_')[1] for k in ground_truth)\n",
        "print(f\"Loaded {len(ground_truth)} labels ({sum(ground_truth.values())} positives).\")\n",
        "\n",
        "# 2. Load test hierarchy\n",
        "print(\"Loading test hierarchy...\")\n",
        "test_tracks = {}\n",
        "with open(file_name_test, 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split('|')\n",
        "        u, t = parts[0], parts[1]\n",
        "        alb = parts[2] if parts[2] != \"None\" else None\n",
        "        art = parts[3] if len(parts)>3 and parts[3]!=\"None\" else None\n",
        "        gens= parts[4:] if len(parts)>4 else []\n",
        "        test_tracks[f\"{u}_{t}\"] = {\n",
        "            'trackID':  t,\n",
        "            'albumID':  alb,\n",
        "            'artistID': art,\n",
        "            'genreIDs': gens\n",
        "        }\n",
        "print(f\"Loaded {len(test_tracks)} test pairs.\")\n",
        "\n",
        "# 3. Load training data\n",
        "print(\"Reading training data...\")\n",
        "train_data     = {}\n",
        "user_ratings   = {}\n",
        "artist_scores  = {}\n",
        "genre_scores   = {}\n",
        "user_genre_rats= {}\n",
        "all_scores     = []\n",
        "\n",
        "with open(file_name_train, 'r') as f:\n",
        "    for line in f:\n",
        "        u, i, s = line.strip().split('|')\n",
        "        s = int(s)\n",
        "        train_data.setdefault(u, {})[i] = s\n",
        "        all_scores.append(s)\n",
        "        user_ratings.setdefault(u, []).append(s)\n",
        "        if i.startswith('artist_'):\n",
        "            artist_scores.setdefault(i, []).append(s)\n",
        "        if i.startswith('genre_'):\n",
        "            genre_scores.setdefault(i, []).append(s)\n",
        "            user_genre_rats.setdefault(u, []).append(s)\n",
        "\n",
        "# 4. Precompute stats\n",
        "global_avg     = np.mean(all_scores) if all_scores else 0.0\n",
        "user_avg       = {u:np.mean(v) for u,v in user_ratings.items()}\n",
        "user_var       = {u:np.std(v)  for u,v in user_ratings.items()}\n",
        "user_cnt       = {u:np.log1p(len(v)) for u,v in user_ratings.items()}\n",
        "artist_avg     = {a:np.mean(v) for a,v in artist_scores.items()}\n",
        "genre_avg      = {g:np.mean(v) for g,v in genre_scores.items()}\n",
        "user_genre_aff = {u:np.mean(v) for u,v in user_genre_rats.items()}\n",
        "\n",
        "# 5. Feature engineering helper\n",
        "def compute_features(u, td):\n",
        "    u_r = train_data.get(u, {})\n",
        "    default = user_avg.get(u, global_avg)\n",
        "\n",
        "    raw_track  = u_r.get(td['trackID'], u_r.get(f\"track_{td['trackID']}\", 0))\n",
        "    raw_album  = u_r.get(td['albumID'], 0) if td['albumID'] else 0\n",
        "    raw_artist = u_r.get(td['artistID'], 0) if td['artistID'] else 0\n",
        "\n",
        "    gs_list = [u_r.get(g,0) for g in td['genreIDs']]\n",
        "    gs_vals = [s for s in gs_list if s>0]\n",
        "    raw_genre = np.mean(gs_vals) if gs_vals else 0\n",
        "\n",
        "    gc     = len(td['genreIDs'])\n",
        "    apr    = artist_avg.get(f\"artist_{td['artistID']}\", global_avg) if td['artistID'] else global_avg\n",
        "    gw     = raw_genre * (len(gs_vals)/gc if gc else 0)\n",
        "    ugaff  = user_genre_aff.get(u, global_avg)\n",
        "\n",
        "    asm = 1 if raw_artist==0 else 0\n",
        "    gsm = 1 if not gs_vals else 0\n",
        "    asw = raw_artist * (1-asm)\n",
        "    uv  = user_var.get(u,0.0)\n",
        "    uc  = user_cnt.get(u,0.0)\n",
        "    a_s = min(raw_artist,100) if raw_artist>0 else user_avg.get(u,global_avg)\n",
        "    g_s = min(raw_genre,100)  if raw_genre>0  else user_avg.get(u,global_avg)\n",
        "\n",
        "    album_score = min(raw_album,100) if raw_album>0 else default\n",
        "    track_score = min(raw_track,100) if raw_track>0 else default\n",
        "    has_album   = 1 if td['albumID']  else 0\n",
        "    has_artist  = 1 if td['artistID'] else 0\n",
        "\n",
        "    return [\n",
        "        a_s, g_s, asm, gsm, asw, uv, uc, gc, apr, gw, ugaff,\n",
        "        album_score, track_score, has_album, has_artist\n",
        "    ]\n",
        "\n",
        "# 6. Build train matrix\n",
        "print(\"Building training matrix...\")\n",
        "X, y = [], []\n",
        "for key, lbl in ground_truth.items():\n",
        "    u, t = key.split('_')\n",
        "    td = test_tracks.get(key, {'trackID':t,'albumID':None,'artistID':None,'genreIDs':[]})\n",
        "    X.append(compute_features(u, td))\n",
        "    y.append(lbl)\n",
        "X = np.array(X);  y = np.array(y)\n",
        "\n",
        "# 7. Split + scale\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X, y, test_size=0.15, stratify=y, random_state=42\n",
        ")\n",
        "scaler  = RobustScaler()\n",
        "X_tr_s  = scaler.fit_transform(X_tr)\n",
        "X_val_s = scaler.transform(X_val)\n",
        "\n",
        "# 8. Hyperparameter tuning\n",
        "print(\"Starting hyperparameter tuning...\")\n",
        "param_dist = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'solver': ['lbfgs', 'liblinear', 'saga'],\n",
        "    'class_weight': [None, 'balanced', {0:1, 1:2}, {0:1, 1:3}]\n",
        "}\n",
        "cv     = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "lr     = LogisticRegression(random_state=42, max_iter=1000)\n",
        "search = RandomizedSearchCV(\n",
        "    lr, param_dist, n_iter=30, scoring='accuracy',\n",
        "    cv=cv, verbose=1, n_jobs=1, random_state=42\n",
        ")\n",
        "search.fit(X_tr_s, y_tr)\n",
        "best_params = search.best_params_\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "\n",
        "# 9. Refit on training split and evaluate on validation\n",
        "best_model = LogisticRegression(**best_params, random_state=42, max_iter=1000)\n",
        "best_model.fit(X_tr_s, y_tr)\n",
        "\n",
        "# Evaluate on held-out validation set\n",
        "y_pred_val = best_model.predict(X_val_s)\n",
        "print(\"Validation Accuracy :\", accuracy_score(y_val, y_pred_val))\n",
        "print(\"Validation Precision:\", precision_score(y_val, y_pred_val))\n",
        "\n",
        "# 10. Retrain on all data\n",
        "print(\"Retraining on full data...\")\n",
        "X_all_s = scaler.fit_transform(X)\n",
        "best_model.fit(X_all_s, y)\n",
        "\n",
        "# 11. Generate submission\n",
        "print(\"Generating submission...\")\n",
        "with open(output_file, 'w') as fout:\n",
        "    fout.write(\"TrackID,Predictor\\n\")\n",
        "    last_u = None\n",
        "    block  = []\n",
        "    for line in open(file_name_test):\n",
        "        parts = line.strip().split('|')\n",
        "        u, t = parts[0], parts[1]\n",
        "        key   = f\"{u}_{t}\"\n",
        "        if last_u is None: last_u = u\n",
        "        if u != last_u:\n",
        "            # write previous user\n",
        "            Xb = np.array([compute_features(last_u, test_tracks[k]) for k in block])\n",
        "            Xb_s = scaler.transform(Xb)\n",
        "            probs = best_model.predict_proba(Xb_s)[:,1]\n",
        "            top3  = set(np.argsort(-probs)[:3])\n",
        "            for idx,k in enumerate(block):\n",
        "                fout.write(f\"{k},{1 if idx in top3 else 0}\\n\")\n",
        "            block = []\n",
        "            last_u = u\n",
        "        block.append(key)\n",
        "    # last user\n",
        "    if block:\n",
        "        Xb = np.array([compute_features(last_u, test_tracks[k]) for k in block])\n",
        "        Xb_s = scaler.transform(Xb)\n",
        "        probs = best_model.predict_proba(Xb_s)[:,1]\n",
        "        top3  = set(np.argsort(-probs)[:3])\n",
        "        for idx,k in enumerate(block):\n",
        "            fout.write(f\"{k},{1 if idx in top3 else 0}\\n\")\n",
        "\n",
        "print(f\"Submission '{output_file}' written.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCqyYMMWaFbK",
        "outputId": "76c51cd8-56a3-49cf-fb56-303681c863bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading ground truth...\n",
            "Loaded 6000 labels (3000 positives).\n",
            "Loading test hierarchy...\n",
            "Loaded 120000 test pairs.\n",
            "Reading training data...\n",
            "Building training matrix...\n",
            "Starting hyperparameter tuning...\n",
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
            "Best hyperparameters: {'solver': 'saga', 'class_weight': None, 'C': 100}\n",
            "Validation Accuracy : 0.8466666666666667\n",
            "Validation Precision: 0.8823529411764706\n",
            "Retraining on full data...\n",
            "Generating submission...\n",
            "Submission 'submission_lr_v5.csv' written.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    StratifiedKFold,\n",
        "    RandomizedSearchCV\n",
        ")\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# File paths\n",
        "file_name_test    = 'testTrack_hierarchy.txt'\n",
        "file_name_train   = 'trainIdx2_matrix.txt'\n",
        "ground_truth_file = 'test2_new.txt'\n",
        "output_file       = 'submission_lr_v9.csv'\n",
        "\n",
        "# 1. Load ground truth\n",
        "print(\"Loading ground truth...\")\n",
        "ground_truth = {}\n",
        "with open(ground_truth_file, 'r') as f:\n",
        "    for line in f:\n",
        "        u, t, l = line.strip().split('|')\n",
        "        ground_truth[f\"{u}_{t}\"] = int(l)\n",
        "gt_users  = set(k.split('_')[0] for k in ground_truth)\n",
        "gt_tracks = set(k.split('_')[1] for k in ground_truth)\n",
        "print(f\"Loaded {len(ground_truth)} labels ({sum(ground_truth.values())} positives).\")\n",
        "\n",
        "# 2. Load test hierarchy\n",
        "print(\"Loading test hierarchy...\")\n",
        "test_tracks = {}\n",
        "with open(file_name_test, 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split('|')\n",
        "        u, t = parts[0], parts[1]\n",
        "        alb = parts[2] if parts[2] != \"None\" else None\n",
        "        art = parts[3] if len(parts)>3 and parts[3]!=\"None\" else None\n",
        "        gens= parts[4:] if len(parts)>4 else []\n",
        "        test_tracks[f\"{u}_{t}\"] = {\n",
        "            'trackID':  t,\n",
        "            'albumID':  alb,\n",
        "            'artistID': art,\n",
        "            'genreIDs': gens\n",
        "        }\n",
        "print(f\"Loaded {len(test_tracks)} test pairs.\")\n",
        "\n",
        "# 3. Load training data\n",
        "print(\"Reading training data...\")\n",
        "train_data     = {}\n",
        "user_ratings   = {}\n",
        "artist_scores  = {}\n",
        "genre_scores   = {}\n",
        "user_genre_rats= {}\n",
        "all_scores     = []\n",
        "user_artist_counts = {}  # New: Track user-artist interaction counts\n",
        "\n",
        "with open(file_name_train, 'r') as f:\n",
        "    for line in f:\n",
        "        u, i, s = line.strip().split('|')\n",
        "        s = int(s)\n",
        "        train_data.setdefault(u, {})[i] = s\n",
        "        all_scores.append(s)\n",
        "        user_ratings.setdefault(u, []).append(s)\n",
        "        if i.startswith('artist_'):\n",
        "            artist_scores.setdefault(i, []).append(s)\n",
        "            user_artist_counts.setdefault(u, {}).setdefault(i, 0)\n",
        "            user_artist_counts[u][i] += 1  # Increment artist interaction count\n",
        "        if i.startswith('genre_'):\n",
        "            genre_scores.setdefault(i, []).append(s)\n",
        "            user_genre_rats.setdefault(u, []).append(s)\n",
        "\n",
        "# 4. Precompute stats\n",
        "global_avg     = np.mean(all_scores) if all_scores else 0.0\n",
        "user_avg       = {u:np.mean(v) for u,v in user_ratings.items()}\n",
        "user_var       = {u:np.std(v)  for u,v in user_ratings.items()}\n",
        "user_cnt       = {u:np.log1p(len(v)) for u,v in user_ratings.items()}\n",
        "artist_avg     = {a:np.mean(v) for a,v in artist_scores.items()}\n",
        "genre_avg      = {g:np.mean(v) for g,v in genre_scores.items()}\n",
        "user_genre_aff = {u:np.mean(v) for u,v in user_genre_rats.items()}\n",
        "\n",
        "# 5. Feature engineering helper\n",
        "def compute_features(u, td):\n",
        "    u_r = train_data.get(u, {})\n",
        "    default = user_avg.get(u, global_avg)\n",
        "\n",
        "    raw_track  = u_r.get(td['trackID'], u_r.get(f\"track_{td['trackID']}\", 0))\n",
        "    raw_album  = u_r.get(td['albumID'], 0) if td['albumID'] else 0\n",
        "    raw_artist = u_r.get(td['artistID'], 0) if td['artistID'] else 0\n",
        "\n",
        "    gs_list = [u_r.get(g,0) for g in td['genreIDs']]\n",
        "    gs_vals = [s for s in gs_list if s>0]\n",
        "    raw_genre = np.mean(gs_vals) if gs_vals else 0\n",
        "\n",
        "    gc     = len(td['genreIDs'])\n",
        "    apr    = artist_avg.get(f\"artist_{td['artistID']}\", global_avg) if td['artistID'] else global_avg\n",
        "    gw     = raw_genre * (len(gs_vals)/gc if gc else 0)\n",
        "    ugaff  = user_genre_aff.get(u, global_avg)\n",
        "\n",
        "    asm = 1 if raw_artist==0 else 0\n",
        "    gsm = 1 if not gs_vals else 0\n",
        "    asw = raw_artist * (1-asm)\n",
        "    uv  = user_var.get(u,0.0)\n",
        "    uc  = user_cnt.get(u,0.0)\n",
        "    a_s = min(raw_artist,100) if raw_artist>0 else user_avg.get(u,global_avg)\n",
        "    g_s = min(raw_genre,100)  if raw_genre>0  else user_avg.get(u,global_avg)\n",
        "\n",
        "    album_score = min(raw_album,100) if raw_album>0 else default\n",
        "    track_score = min(raw_track,100) if raw_track>0 else default\n",
        "    has_album   = 1 if td['albumID']  else 0\n",
        "    has_artist  = 1 if td['artistID'] else 0\n",
        "\n",
        "    # New: User-artist interaction count\n",
        "    artist_count = user_artist_counts.get(u, {}).get(f\"artist_{td['artistID']}\", 0) if td['artistID'] else 0\n",
        "\n",
        "    return [\n",
        "        a_s, g_s, asm, gsm, asw, uv, uc, gc, apr, gw, ugaff,\n",
        "        album_score, track_score, has_album, has_artist, artist_count\n",
        "    ]\n",
        "\n",
        "# 6. Build train matrix\n",
        "print(\"Building training matrix...\")\n",
        "X, y = [], []\n",
        "for key, lbl in ground_truth.items():\n",
        "    u, t = key.split('_')\n",
        "    td = test_tracks.get(key, {'trackID':t,'albumID':None,'artistID':None,'genreIDs':[]})\n",
        "    X.append(compute_features(u, td))\n",
        "    y.append(lbl)\n",
        "X = np.array(X);  y = np.array(y)\n",
        "\n",
        "# 7. Split + scale\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X, y, test_size=0.15, stratify=y, random_state=42\n",
        ")\n",
        "scaler  = RobustScaler()\n",
        "X_tr_s  = scaler.fit_transform(X_tr)\n",
        "X_val_s = scaler.transform(X_val)\n",
        "\n",
        "# 8. Hyperparameter tuning\n",
        "print(\"Starting hyperparameter tuning...\")\n",
        "param_dist = {\n",
        "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
        "    'classifier__solver': ['liblinear'],\n",
        "    'classifier__class_weight': [None, 'balanced', {0:1, 1:2}, {0:1, 1:3}],\n",
        "    'select__k': [10, 12, 14]\n",
        "}\n",
        "cv     = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "pipeline = Pipeline([\n",
        "    ('select', SelectKBest(score_func=f_classif)),\n",
        "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
        "])\n",
        "search = RandomizedSearchCV(\n",
        "    pipeline, param_dist, n_iter=30, scoring='accuracy',\n",
        "    cv=cv, verbose=1, n_jobs=1, random_state=42\n",
        ")\n",
        "search.fit(X_tr_s, y_tr)\n",
        "best_params = search.best_params_\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "\n",
        "# 9. Refit on training split and evaluate on validation\n",
        "best_model = Pipeline([\n",
        "    ('select', SelectKBest(score_func=f_classif, k=best_params['select__k'])),\n",
        "    ('classifier', LogisticRegression(\n",
        "        C=best_params['classifier__C'],\n",
        "        solver=best_params['classifier__solver'],\n",
        "        class_weight=best_params['classifier__class_weight'],\n",
        "        random_state=42,\n",
        "        max_iter=2000\n",
        "    ))\n",
        "])\n",
        "best_model.fit(X_tr_s, y_tr)\n",
        "\n",
        "# Evaluate on held-out validation set\n",
        "y_pred_val = best_model.predict(X_val_s)\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "print(\"Validation Accuracy :\", val_accuracy)\n",
        "print(\"Validation Precision:\", precision_score(y_val, y_pred_val))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred_val))\n",
        "\n",
        "# 10. Evaluate on full ground truth\n",
        "print(\"Evaluating on full ground truth...\")\n",
        "X_all_s = scaler.fit_transform(X)\n",
        "best_model.fit(X_all_s, y)\n",
        "y_pred_all = best_model.predict(X_all_s)\n",
        "ground_truth_accuracy = accuracy_score(y, y_pred_all)\n",
        "print(\"Ground Truth Accuracy:\", ground_truth_accuracy)\n",
        "\n",
        "# 11. Generate submission\n",
        "print(\"Generating submission...\")\n",
        "with open(output_file, 'w') as fout:\n",
        "    fout.write(\"TrackID,Predictor\\n\")\n",
        "    last_u = None\n",
        "    block  = []\n",
        "    for line in open(file_name_test):\n",
        "        parts = line.strip().split('|')\n",
        "        u, t = parts[0], parts[1]\n",
        "        key   = f\"{u}_{t}\"\n",
        "        if last_u is None: last_u = u\n",
        "        if u != last_u:\n",
        "            # write previous user\n",
        "            Xb = np.array([compute_features(last_u, test_tracks[k]) for k in block])\n",
        "            Xb_s = scaler.transform(Xb)\n",
        "            probs = best_model.predict_proba(Xb_s)[:,1]\n",
        "            top3  = set(np.argsort(-probs)[:3])\n",
        "            for idx,k in enumerate(block):\n",
        "                fout.write(f\"{k},{1 if idx in top3 else 0}\\n\")\n",
        "            block = []\n",
        "            last_u = u\n",
        "        block.append(key)\n",
        "    # last user\n",
        "    if block:\n",
        "        Xb = np.array([compute_features(last_u, test_tracks[k]) for k in block])\n",
        "        Xb_s = scaler.transform(Xb)\n",
        "        probs = best_model.predict_proba(Xb_s)[:,1]\n",
        "        top3  = set(np.argsort(-probs)[:3])\n",
        "        for idx,k in enumerate(block):\n",
        "            fout.write(f\"{k},{1 if idx in top3 else 0}\\n\")\n",
        "\n",
        "print(f\"Submission '{output_file}' written.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rut4YdxZgitG",
        "outputId": "79a18cd7-d09e-419e-b742-85092898039c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading ground truth...\n",
            "Loaded 6000 labels (3000 positives).\n",
            "Loading test hierarchy...\n",
            "Loaded 120000 test pairs.\n",
            "Reading training data...\n",
            "Building training matrix...\n",
            "Starting hyperparameter tuning...\n",
            "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 8 10 15] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best hyperparameters: {'select__k': 14, 'classifier__solver': 'liblinear', 'classifier__class_weight': None, 'classifier__C': 100}\n",
            "Validation Accuracy : 0.8466666666666667\n",
            "Validation Precision: 0.8823529411764706\n",
            "Confusion Matrix:\n",
            " [[402  48]\n",
            " [ 90 360]]\n",
            "Evaluating on full ground truth...\n",
            "Ground Truth Accuracy: 0.8508333333333333\n",
            "Generating submission...\n",
            "Submission 'submission_lr_v9.csv' written.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, confusion_matrix\n",
        "from sklearn.model_selection import (\n",
        "    train_test_split,\n",
        "    StratifiedKFold,\n",
        "    RandomizedSearchCV\n",
        ")\n",
        "\n",
        "# File paths\n",
        "file_name_test    = 'testTrack_hierarchy.txt'\n",
        "file_name_train   = 'trainIdx2_matrix.txt'\n",
        "ground_truth_file = 'test2_new.txt'\n",
        "output_file       = 'submission_xgb_v10.csv'\n",
        "\n",
        "# 1. Load ground truth\n",
        "print(\"Loading ground truth...\")\n",
        "ground_truth = {}\n",
        "with open(ground_truth_file, 'r') as f:\n",
        "    for line in f:\n",
        "        u, t, l = line.strip().split('|')\n",
        "        ground_truth[f\"{u}_{t}\"] = int(l)\n",
        "gt_users  = set(k.split('_')[0] for k in ground_truth)\n",
        "gt_tracks = set(k.split('_')[1] for k in ground_truth)\n",
        "print(f\"Loaded {len(ground_truth)} labels ({sum(ground_truth.values())} positives).\")\n",
        "\n",
        "# 2. Load test hierarchy\n",
        "print(\"Loading test hierarchy...\")\n",
        "test_tracks = {}\n",
        "with open(file_name_test, 'r') as f:\n",
        "    for line in f:\n",
        "        parts = line.strip().split('|')\n",
        "        u, t = parts[0], parts[1]\n",
        "        alb = parts[2] if parts[2] != \"None\" else None\n",
        "        art = parts[3] if len(parts)>3 and parts[3]!=\"None\" else None\n",
        "        gens= parts[4:] if len(parts)>4 else []\n",
        "        test_tracks[f\"{u}_{t}\"] = {\n",
        "            'trackID':  t,\n",
        "            'albumID':  alb,\n",
        "            'artistID': art,\n",
        "            'genreIDs': gens\n",
        "        }\n",
        "print(f\"Loaded {len(test_tracks)} test pairs.\")\n",
        "\n",
        "# 3. Load training data\n",
        "print(\"Reading training data...\")\n",
        "train_data     = {}\n",
        "user_ratings   = {}\n",
        "artist_scores  = {}\n",
        "genre_scores   = {}\n",
        "user_genre_rats= {}\n",
        "all_scores     = []\n",
        "user_artist_counts = {}\n",
        "user_genre_counts  = {}  # New: Track user-genre interaction counts\n",
        "\n",
        "with open(file_name_train, 'r') as f:\n",
        "    for line in f:\n",
        "        u, i, s = line.strip().split('|')\n",
        "        s = int(s)\n",
        "        train_data.setdefault(u, {})[i] = s\n",
        "        all_scores.append(s)\n",
        "        user_ratings.setdefault(u, []).append(s)\n",
        "        if i.startswith('artist_'):\n",
        "            artist_scores.setdefault(i, []).append(s)\n",
        "            user_artist_counts.setdefault(u, {}).setdefault(i, 0)\n",
        "            user_artist_counts[u][i] += 1\n",
        "        if i.startswith('genre_'):\n",
        "            genre_scores.setdefault(i, []).append(s)\n",
        "            user_genre_rats.setdefault(u, []).append(s)\n",
        "            user_genre_counts.setdefault(u, {}).setdefault(i, 0)\n",
        "            user_genre_counts[u][i] += 1\n",
        "\n",
        "# 4. Precompute stats\n",
        "global_avg     = np.mean(all_scores) if all_scores else 0.0\n",
        "user_avg       = {u:np.mean(v) for u,v in user_ratings.items()}\n",
        "user_var       = {u:np.std(v)  for u,v in user_ratings.items()}\n",
        "user_cnt       = {u:np.log1p(len(v)) for u,v in user_ratings.items()}\n",
        "artist_avg     = {a:np.mean(v) for a,v in artist_scores.items()}\n",
        "genre_avg      = {g:np.mean(v) for g,v in genre_scores.items()}\n",
        "user_genre_aff = {u:np.mean(v) for u,v in user_genre_rats.items()}\n",
        "\n",
        "# 5. Feature engineering helper\n",
        "def compute_features(u, td):\n",
        "    u_r = train_data.get(u, {})\n",
        "    default = user_avg.get(u, global_avg)\n",
        "\n",
        "    raw_track  = u_r.get(td['trackID'], u_r.get(f\"track_{td['trackID']}\", 0))\n",
        "    raw_album  = u_r.get(td['albumID'], 0) if td['albumID'] else 0\n",
        "    raw_artist = u_r.get(td['artistID'], 0) if td['artistID'] else 0\n",
        "\n",
        "    gs_list = [u_r.get(g,0) for g in td['genreIDs']]\n",
        "    gs_vals = [s for s in gs_list if s>0]\n",
        "    raw_genre = np.mean(gs_vals) if gs_vals else 0\n",
        "\n",
        "    gc     = len(td['genreIDs'])\n",
        "    apr    = artist_avg.get(f\"artist_{td['artistID']}\", global_avg) if td['artistID'] else global_avg\n",
        "    gw     = raw_genre * (len(gs_vals)/gc if gc else 0)\n",
        "    ugaff  = user_genre_aff.get(u, global_avg)\n",
        "\n",
        "    asm = 1 if raw_artist==0 else 0\n",
        "    gsm = 1 if not gs_vals else 0\n",
        "    asw = raw_artist * (1-asm)\n",
        "    uv  = user_var.get(u,0.0)\n",
        "    uc  = user_cnt.get(u,0.0)\n",
        "    a_s = min(raw_artist,100) if raw_artist>0 else user_avg.get(u,global_avg)\n",
        "    g_s = min(raw_genre,100)  if raw_genre>0  else user_avg.get(u,global_avg)\n",
        "\n",
        "    album_score = min(raw_album,100) if raw_album>0 else default\n",
        "    track_score = min(raw_track,100) if raw_track>0 else default\n",
        "    has_album   = 1 if td['albumID']  else 0\n",
        "    has_artist  = 1 if td['artistID'] else 0\n",
        "\n",
        "    artist_count = user_artist_counts.get(u, {}).get(f\"artist_{td['artistID']}\", 0) if td['artistID'] else 0\n",
        "    genre_count  = sum(user_genre_counts.get(u, {}).get(g, 0) for g in td['genreIDs']) if td['genreIDs'] else 0\n",
        "\n",
        "    return [\n",
        "        a_s, g_s, asm, gsm, asw, uv, uc, gc, apr, gw, ugaff,\n",
        "        album_score, track_score, has_album, has_artist, artist_count, genre_count\n",
        "    ]\n",
        "\n",
        "# 6. Build train matrix\n",
        "print(\"Building training matrix...\")\n",
        "X, y = [], []\n",
        "for key, lbl in ground_truth.items():\n",
        "    u, t = key.split('_')\n",
        "    td = test_tracks.get(key, {'trackID':t,'albumID':None,'artistID':None,'genreIDs':[]})\n",
        "    X.append(compute_features(u, td))\n",
        "    y.append(lbl)\n",
        "X = np.array(X);  y = np.array(y)\n",
        "\n",
        "# 7. Split + scale\n",
        "X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "    X, y, test_size=0.15, stratify=y, random_state=42\n",
        ")\n",
        "scaler  = RobustScaler()\n",
        "X_tr_s  = scaler.fit_transform(X_tr)\n",
        "X_val_s = scaler.transform(X_val)\n",
        "\n",
        "# 8. Hyperparameter tuning\n",
        "print(\"Starting hyperparameter tuning...\")\n",
        "param_dist = {\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'learning_rate': [0.01, 0.1, 0.3],\n",
        "    'n_estimators': [100, 200],\n",
        "    'subsample': [0.8, 1.0],\n",
        "    'colsample_bytree': [0.8, 1.0]\n",
        "}\n",
        "cv     = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "model  = XGBClassifier(random_state=42, eval_metric='logloss', early_stopping_rounds=10)\n",
        "search = RandomizedSearchCV(\n",
        "    model, param_dist, n_iter=20, scoring='accuracy',\n",
        "    cv=cv, verbose=1, n_jobs=1, random_state=42\n",
        ")\n",
        "search.fit(X_tr_s, y_tr, eval_set=[(X_val_s, y_val)], verbose=False)\n",
        "best_params = search.best_params_\n",
        "print(\"Best hyperparameters:\", best_params)\n",
        "\n",
        "# 9. Refit on training split and evaluate on validation\n",
        "best_model = XGBClassifier(\n",
        "    **best_params, random_state=42, eval_metric='logloss', early_stopping_rounds=10\n",
        ")\n",
        "best_model.fit(X_tr_s, y_tr, eval_set=[(X_val_s, y_val)], verbose=False)\n",
        "\n",
        "# Evaluate on held-out validation set\n",
        "y_pred_val = best_model.predict(X_val_s)\n",
        "val_accuracy = accuracy_score(y_val, y_pred_val)\n",
        "print(\"Validation Accuracy :\", val_accuracy)\n",
        "print(\"Validation Precision:\", precision_score(y_val, y_pred_val))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_val, y_pred_val))\n",
        "\n",
        "# 10. Evaluate on full ground truth\n",
        "print(\"Evaluating on full ground truth...\")\n",
        "X_all_s = scaler.fit_transform(X)\n",
        "best_model.fit(X_all_s, y, eval_set=[(X_all_s, y)], verbose=False)\n",
        "y_pred_all = best_model.predict(X_all_s)\n",
        "ground_truth_accuracy = accuracy_score(y, y_pred_all)\n",
        "print(\"Ground Truth Accuracy:\", ground_truth_accuracy)\n",
        "\n",
        "# 11. Generate submission\n",
        "print(\"Generating submission...\")\n",
        "with open(output_file, 'w') as fout:\n",
        "    fout.write(\"TrackID,Predictor\\n\")\n",
        "    last_u = None\n",
        "    block  = []\n",
        "    for line in open(file_name_test):\n",
        "        parts = line.strip().split('|')\n",
        "        u, t = parts[0], parts[1]\n",
        "        key   = f\"{u}_{t}\"\n",
        "        if last_u is None: last_u = u\n",
        "        if u != last_u:\n",
        "            # write previous user\n",
        "            Xb = np.array([compute_features(last_u, test_tracks[k]) for k in block])\n",
        "            Xb_s = scaler.transform(Xb)\n",
        "            probs = best_model.predict_proba(Xb_s)[:,1]\n",
        "            top3  = set(np.argsort(-probs)[:3])\n",
        "            for idx,k in enumerate(block):\n",
        "                fout.write(f\"{k},{1 if idx in top3 else 0}\\n\")\n",
        "            block = []\n",
        "            last_u = u\n",
        "        block.append(key)\n",
        "    # last user\n",
        "    if block:\n",
        "        Xb = np.array([compute_features(last_u, test_tracks[k]) for k in block])\n",
        "        Xb_s = scaler.transform(Xb)\n",
        "        probs = best_model.predict_proba(Xb_s)[:,1]\n",
        "        top3  = set(np.argsort(-probs)[:3])\n",
        "        for idx,k in enumerate(block):\n",
        "            fout.write(f\"{k},{1 if idx in top3 else 0}\\n\")\n",
        "\n",
        "print(f\"Submission '{output_file}' written.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1U8mvJ41k6Hq",
        "outputId": "9c9bf62e-5383-4f57-8fa6-f599329337ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading ground truth...\n",
            "Loaded 6000 labels (3000 positives).\n",
            "Loading test hierarchy...\n",
            "Loaded 120000 test pairs.\n",
            "Reading training data...\n",
            "Building training matrix...\n",
            "Starting hyperparameter tuning...\n",
            "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
            "Best hyperparameters: {'subsample': 0.8, 'n_estimators': 200, 'max_depth': 3, 'learning_rate': 0.3, 'colsample_bytree': 1.0}\n",
            "Validation Accuracy : 0.8488888888888889\n",
            "Validation Precision: 0.8944723618090452\n",
            "Confusion Matrix:\n",
            " [[408  42]\n",
            " [ 94 356]]\n",
            "Evaluating on full ground truth...\n",
            "Ground Truth Accuracy: 0.8985\n",
            "Generating submission...\n",
            "Submission 'submission_xgb_v10.csv' written.\n"
          ]
        }
      ]
    }
  ]
}